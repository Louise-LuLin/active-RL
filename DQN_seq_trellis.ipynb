{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Cuda: True ===\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable  \n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import re\n",
    "import copy\n",
    "from itertools import combinations \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "import nltk\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"== Cuda: {} ===\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Loader\n",
    "class BuildDataLoader:\n",
    "    \n",
    "    def __init__(self, source, folder, num_flag, embed_flag):\n",
    "        self.sequence = []\n",
    "        self.word_dict = {}\n",
    "        self.label_dict = {}\n",
    "        self.num_flag = num_flag\n",
    "        self.embed_flag = embed_flag\n",
    "        self.folder = folder\n",
    "\n",
    "        if source == 'conll':\n",
    "            with open(folder + \"train.txt\", 'r') as file:\n",
    "                x=[]\n",
    "                y=[]\n",
    "                for line in file:\n",
    "                    tokens = line.replace(\"\\n\",'').split()\n",
    "                    if len(tokens) < 1:\n",
    "                        self.sequence.append((x,y))\n",
    "                        x = []\n",
    "                        y = []\n",
    "                    else:\n",
    "                        char = tokens[0]\n",
    "                        label = tokens[2]\n",
    "                        if self.num_flag and char.replace('.','').isdigit():\n",
    "                            char = 'NUM'\n",
    "                        x.append(char)\n",
    "                        y.append(label)\n",
    "                        if char not in self.word_dict:\n",
    "                            self.word_dict[char] = len(self.word_dict)\n",
    "                        if label not in self.label_dict:\n",
    "                            self.label_dict[label] = len(self.label_dict)\n",
    "        else:\n",
    "            with open(folder + '_string.txt', 'r') as x_file, open(folder + '_label.txt', 'r') as y_file: \n",
    "                for x, y in zip(x_file, y_file):\n",
    "                    x = [char for char in x.replace(\"\\n\",'')]\n",
    "                    y = y.replace(\"\\n\",'').split(',')\n",
    "                    if(len(y) > 1):\n",
    "                        if len(y[-1]) == 0:\n",
    "                            y = y[:-1]\n",
    "                        if self.num_flag:\n",
    "                            for i in range(len(x)):\n",
    "                                if x[i].isdigit():\n",
    "                                    x[i] = 'x'\n",
    "                        for char, label in zip(x, y):\n",
    "                            if char not in self.word_dict:\n",
    "                                self.word_dict[char] = len(self.word_dict)\n",
    "                            if label not in self.label_dict:\n",
    "                                self.label_dict[label] = len(self.label_dict)\n",
    "                        self.sequence.append((x, y))\n",
    "        \n",
    "        lens = []\n",
    "        for seq in self.sequence:\n",
    "            lens.append(len(seq[0]))\n",
    "        self.max_len = max(lens)\n",
    "    \n",
    "    def shuffle(self, seed = 4):\n",
    "        random.Random(4).shuffle(self.sequence)\n",
    "    \n",
    "    def seqs2Tensor(self, sequence):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            char_embed = []\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    char_embed.append(wv[char])\n",
    "            tensor = torch.from_numpy(np.array(char_embed)).type(torch.FloatTensor)\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "        else:\n",
    "            tensor = torch.zeros(len(sequence[0]), len(self.word_dict), device=device)\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    tensor[j][self.word_dict[char]] = 1\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    def get_embed_size(self):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            return wv.vector_size\n",
    "        else:\n",
    "            return len(self.word_dict)\n",
    "    \n",
    "    def get_word_dict(self):\n",
    "        return self.word_dict\n",
    "    \n",
    "    def get_label_dict(self):\n",
    "        return self.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF\n",
    "class CrfModel(object):\n",
    "    \n",
    "    def __init__(self, data, feature):\n",
    "        self.label_dict = data.label_dict\n",
    "        self.word_dict = data.word_dict\n",
    "        self.num_flag = data.num_flag\n",
    "        self.max_len = data.max_len\n",
    "        self.feature = feature\n",
    "        \n",
    "        self.crf = CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "        \n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "        print ('label dict size: {}'.format(len(self.label_dict)))\n",
    "        print ('word dict size: {}'.format(len(self.word_dict)))\n",
    "    def reset(self):\n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "    def char2feature(self, sent, i):\n",
    "        # for current character\n",
    "        w = sent[i]\n",
    "        if self.num_flag and w.isdigit():\n",
    "            w = 'x'\n",
    "        features = {'0:word': w}\n",
    "        # for previous character\n",
    "        if i > 0:\n",
    "            w = sent[i-1]\n",
    "            if self.num_flag and w.isdigit():\n",
    "                w = 'x'\n",
    "            features.update({'-1:word': w})\n",
    "        # for next character\n",
    "        if i < len(sent)-1:\n",
    "            w = sent[i+1]\n",
    "            if self.num_flag and w.isdigit():\n",
    "                w = 'x'\n",
    "            features.update({'+1:word': w})\n",
    "        return features\n",
    "    \n",
    "    def add_instances(self, sequences):\n",
    "        for seq in sequences:\n",
    "            x = seq[0]\n",
    "            y = seq[1]\n",
    "            self.X_train.append([self.char2feature(x, i) for i in range(len(x))])\n",
    "            self.Y_train.append(y)\n",
    "    \n",
    "    def compute_confidence(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        y_pred = self.crf.tagger_.tag(x)\n",
    "#         prob_norm = math.exp(math.log(self.crf.tagger_.probability(y_pred)) / len(x))\n",
    "        prob_norm = pow(self.crf.tagger_.probability(y_pred), 1. / len(x))\n",
    "    \n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        prob_list = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            prob_list.append(max(marginal_prob))\n",
    "        return (prob_list, sum(prob_list), prob_norm)\n",
    "    \n",
    "    def compute_entropy(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        self.crf.tagger_.set(x)\n",
    "        entropy_seq = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            entropy_seq.append(scipy.stats.entropy(marginal_prob))\n",
    "        return (entropy_seq, sum(entropy_seq))\n",
    "    \n",
    "    def train(self):\n",
    "        self.crf.fit(self.X_train, self.Y_train) \n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def predict(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        return self.crf.tagger_.tag(x)    \n",
    "    \n",
    "    def evaluate_acc(self, sequences):\n",
    "        # Calculate phrase-level accuracy and out-of-phrase accuracy\n",
    "        X_test = [[self.char2feature(seq[0], i) for i in range(len(seq[0]))] for seq in sequences]\n",
    "        Y_test = [seq[1] for seq in sequences]\n",
    "        Y_pred = self.crf.predict(X_test)\n",
    "        \n",
    "        # Consider the accuracy in phrase level.\n",
    "        in_cnt,  in_crt = 0, 0    # Total/correct number of phrases\n",
    "        out_cnt, out_crt = 0, 0   # Total/correct number of \"o\"\n",
    "        all_cnt, all_crt = 0, 0   # Total/correct number of all words\n",
    "\n",
    "        acc = []\n",
    "        for y_test, y_pred in zip(Y_test, Y_pred):\n",
    "            cnt, crt = 0, 0\n",
    "            correct_flag = False\n",
    "            for j in range(len(y_test)):\n",
    "                all_cnt += 1\n",
    "                cnt += 1\n",
    "                if y_test[j] == y_pred[j]:\n",
    "                    all_crt += 1\n",
    "                    crt += 1\n",
    "\n",
    "                # If the character is a beginning-of-phrase.\n",
    "                if y_test[j][0] == 'b' or y_test[j][0] == 'B':\n",
    "                    in_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                        correct_flag = True\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an inside-of-phrase.\n",
    "                elif y_test[j][0] == 'i' or y_test[j][0] == 'I':\n",
    "                    if y_test[j] != y_pred[j]:\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an out-of-phrase.\n",
    "                elif y_test[j][0] == 'o' or y_test[j][0] == 'O':\n",
    "                    out_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        out_crt += 1\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                            correct_flag = False\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                            correct_flag = False\n",
    "\n",
    "            acc.append(crt/cnt)\n",
    "            # For the case where the phrase is at the end of a string.\n",
    "            if correct_flag:\n",
    "                in_crt += 1\n",
    "        in_acc = 0 if in_cnt == 0 else in_crt/in_cnt\n",
    "        out_acc = 0 if out_cnt == 0 else out_crt/out_cnt\n",
    "        all_acc = 0 if all_cnt == 0 else all_crt/all_cnt \n",
    "            \n",
    "        return in_acc, out_acc, all_acc, sum(acc)/len(acc)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        loc = {'0':0, '-1':1, '+1':2}\n",
    "        if self.feature == 'all':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict) + len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = len(loc) * len(self.word_dict) + self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "        elif self.feature == 'node':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "        else:\n",
    "            paras = torch.zeros(len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "                \n",
    "        paras = paras.unsqueeze(0).unsqueeze(0).to(device) # batch, channel, h, w\n",
    "        return paras\n",
    "    \n",
    "    def get_marginals(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        self.crf.tagger_.set(x)\n",
    "        marginals = torch.zeros(len(self.label_dict), self.max_len, device=device)\n",
    "        for i in range(len(x)):\n",
    "            for lbl in label_list:\n",
    "                marginals[self.label_dict[lbl]][i] = self.crf.tagger_.marginal(lbl, i)\n",
    "        return marginals.unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    def get_label_size(self):\n",
    "        return len(self.label_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a set of string by n-grams.\n",
    "def string_vectorize(Xs_list):\n",
    "    vc = CV(analyzer='char_wb', ngram_range=(3, 4), min_df=1, token_pattern='[a-z]{2,}')\n",
    "    name = []\n",
    "    for i in Xs_list:\n",
    "        s = re.findall('(?i)[a-z]{2,}', \"\".join(str(x) for x in i))\n",
    "        name.append(' '.join(s))\n",
    "    vc.fit(name)\n",
    "    vec = vc.transform(name).toarray()\n",
    "    # print(name)\n",
    "    # print(vec)\n",
    "    dictionary = vc.get_feature_names()\n",
    "    return vec, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer: a cyclic buffer of bounded size that holds the transitions observed recently\n",
    "Transition = namedtuple('Transition',\n",
    "                       ('state', 'action', 'next_state', 'reward', 'sequences'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network\n",
    "class DQNtrellis(nn.Module):\n",
    "    \n",
    "    def __init__(self, para_h, para_w, w_dim, rnn_hidden):\n",
    "        super(DQNtrellis, self).__init__()\n",
    "        \n",
    "        # CNN for CRF trellis\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=20,   \n",
    "                kernel_size=(para_h, 3),              \n",
    "                stride=1,        \n",
    "            )\n",
    "        self.bn1 = nn.BatchNorm2d(20)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_w_out(size, kernel_w_size = 3, stride = 1):\n",
    "            return (size - (kernel_w_size - 1) - 1) // stride  + 1\n",
    "        def conv2d_h_out(size, kernel_h_size = para_h, stride = 1):\n",
    "            return (size - (kernel_h_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        \n",
    "        convw = conv2d_w_out(para_w)\n",
    "        convh = conv2d_h_out(para_h)\n",
    "        linear_input_size = convw * convh * 20\n",
    "        \n",
    "        self.fc1 = nn.Linear(linear_input_size, rnn_hidden)\n",
    "#         self.fc2 = nn.Linear(1, rnn_hidden)\n",
    "        \n",
    "        # LSTM for w sequence\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=w_dim,\n",
    "            hidden_size=rnn_hidden, \n",
    "            num_layers=1,\n",
    "            batch_first=True,  # input＆output (batch，time_step，input_size)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(2 * rnn_hidden, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, crf_x, seq_x):\n",
    "        # CNN\n",
    "        x1 = F.relu(self.bn1(self.conv1(crf_x)))\n",
    "#         x1 = F.relu(self.bn2(self.conv2(x1)))\n",
    "#         x1 = F.relu(self.bn3(self.conv3(x1)))\n",
    "        x1 = F.relu(self.fc1(x1.view(x1.size(0), -1)))\n",
    "        \n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size) \n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out,_ = self.rnn(seq_x, None) \n",
    "        # output of last time step\n",
    "#         rnn_out = self.out(r_out[:, -1, :])\n",
    "        x2 = r_out[:, -1, :]\n",
    "    \n",
    "#         x3 = self.fc2(conf_test)\n",
    "#         x = torch.cat((x1, x2, x3), 1)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        return self.fc(x) # flatten the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(crf, sequences, greedy_select):\n",
    "    max_idx = 0\n",
    "    \n",
    "    if greedy_select == 'te':\n",
    "        prob_list = []\n",
    "        for seq in sequences:\n",
    "            (prob_per_token, prob_sum) = crf.compute_entropy(seq)\n",
    "            prob_list.append(prob_sum/len(seq[1]))\n",
    "        # normalize\n",
    "        mean_prob = np.mean(prob_list)\n",
    "        std_prob = np.std(prob_list)\n",
    "        prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(sequences))]\n",
    "        max_idx = np.argsort(np.array(prob_list), kind='mergesort').tolist()[::-1][0]\n",
    "    \n",
    "    max_q_value = policy_net(crf.get_marginals(sequences[max_idx]), data.seqs2Tensor(sequences[max_idx]))\n",
    "\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = 0.3\n",
    "#     eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "#         math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \n",
    "    if sample < eps_threshold:\n",
    "        return (0, max_idx, max_q_value)\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "#         q_value = policy_net(get_state_action(seq, state))\n",
    "        q_value = policy_net(crf.get_marginals(seq), data.seqs2Tensor(seq))\n",
    "        if max_q_value < q_value:\n",
    "            max_q_value = q_value\n",
    "            max_idx = i\n",
    "    return (1, max_idx, max_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_state_action(crf, sequences):\n",
    "    max_idx = 0\n",
    "    max_q_value = target_net(crf.get_marginals(sequences[max_idx]), data.seqs2Tensor(sequences[max_idx]))\n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "        q_value = target_net(crf.get_marginals(seq), data.seqs2Tensor(seq))\n",
    "        if max_q_value < q_value:\n",
    "            max_q_value = q_value\n",
    "            max_idx = i\n",
    "    return (max_idx, max_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data distribution\n",
    "def gen_dataDistr(sequences):\n",
    "    data_q = {}\n",
    "    for seq in sequences:\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        if x not in data_q:\n",
    "            data_q[x] = 1\n",
    "        else:\n",
    "            data_q[x] += 1\n",
    "    return data_q\n",
    "\n",
    "def calculate_reward(crf, validation_list, test_list, sim_weight, trans_flag):\n",
    "    if trans_flag == 'test3T' or trans_flag == 'test2T':\n",
    "        source_seqs = test_list\n",
    "        target_seqs = test_list\n",
    "    elif trans_flag == 'valid3V' or trans_flag == 'valid2V':\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = validation_list\n",
    "    else:\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = test_list\n",
    "\n",
    "    source_q = gen_dataDistr(source_seqs)\n",
    "    target_q = gen_dataDistr(target_seqs)\n",
    "    acc_reweight = []\n",
    "    idx = []\n",
    "    for i, seq in enumerate(source_seqs):\n",
    "        _, _, _, acc = crf.evaluate_acc([seq])\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        ratio_source = source_q[x] / len(source_seqs)\n",
    "        if trans_flag == 'kmers':\n",
    "            acc_reweight.append(sim_weight[i] * acc)\n",
    "            idx.append(i)\n",
    "        elif x in target_q:\n",
    "            ratio_target = target_q[x] / len(target_seqs)\n",
    "            if trans_flag == 'test2T' or trans_flag == 'valid2V' or trans_flag == 'valid2T':\n",
    "                acc_reweight.append(acc)\n",
    "                idx.append(i)\n",
    "            elif trans_flag == 'test3T' or trans_flag == 'valid3V':\n",
    "                acc_reweight.append(ratio_target * acc)\n",
    "                idx.append(i)\n",
    "            else:\n",
    "                acc_reweight.append(ratio_target/ratio_source * acc)\n",
    "                idx.append(ratio_target/ratio_source)\n",
    "            \n",
    "    minidx = np.argsort(acc_reweight)\n",
    "#     errseq = [source_seqs[idx[i]] for i in minidx[:10]]\n",
    "    errseq = []\n",
    "    pred = [crf.predict(err) for err in errseq]\n",
    "    acc = sum(acc_reweight) / sum(idx)\n",
    "    return (acc, errseq, pred)\n",
    " \n",
    "    # confidence on test set\n",
    "#     conf = 0\n",
    "#     for seq in test_list:\n",
    "#         conf += crf.compute_entropy(seq)[-1]/len(seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    \n",
    "#     state_batch = []\n",
    "#     for i in range(len(batch.state)):\n",
    "#         state_actions.append(get_state_action(batch.action[i], batch.state[i]))\n",
    "    \n",
    "    state_batch  = torch.cat(batch.state)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    # padding sequences\n",
    "    seq_lengths = []\n",
    "    embed_dim = 0\n",
    "    batch_size = 0\n",
    "    for a in batch.action:\n",
    "        seq_lengths.append(a.shape[1])\n",
    "        embed_dim = a.shape[2]\n",
    "        batch_size += 1\n",
    "    max_len = max(seq_lengths)\n",
    "    action_batch = torch.zeros((batch_size, max_len, embed_dim), device=device)\n",
    "    for i, a in enumerate(batch.action):\n",
    "        a = a.squeeze(0)\n",
    "        if a.shape[0] < max_len:\n",
    "            padding = torch.zeros((max_len - a.shape[0], embed_dim), device=device)\n",
    "            a = torch.cat([a, padding])\n",
    "        action_batch[i] = a\n",
    "#     action_batch = torch.nn.utils.rnn.pack_padded_sequence(actions, seq_lengths, batch_first=True, enforce_sorted=False)  \n",
    "\n",
    "    next_reward = [s for s in batch.next_state if s is not None]\n",
    "    \n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = torch.cat(next_reward).squeeze(1)\n",
    "#     print (non_final_mask)\n",
    "#     print (next_reward)\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    policy_net.train()\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Q-function\n",
    "BATCH_SIZE = 5\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 20\n",
    "TARGET_UPDATE = 20\n",
    "\n",
    "SOURCE = 'conll'\n",
    "METHOD = 'Trellis'\n",
    "if SOURCE == 'conll':\n",
    "    DATA_PATH = \"./datasets/conll2000/\" + SOURCE\n",
    "else:\n",
    "    DATA_PATH = \"./datasets/building/\" + SOURCE\n",
    "CRF_PRETRAIN_SIZE = 5\n",
    "AGENT_PRETRAIN_SIZE = 15\n",
    "CANDIDATE_SIZE = 600\n",
    "VALIDATE_SIZE = 200\n",
    "TEST_SIZE = 200\n",
    "BUDGET = 75\n",
    "FEAT = 'all' # all or node or edge\n",
    "GREEDY = 'te' # rand or te\n",
    "FIX_FLAG = False\n",
    "NUM_FLAG = True\n",
    "EMBED_FLAG = True\n",
    "TRANS = 'valid2V' # kmers or valid2V or valid2T or test2V or test2T\n",
    "LOOP_SIZE = 5\n",
    "LOOP_CANDI = 3\n",
    "INITIAL_FLAG = True\n",
    "REWARD = 'acc' # acc, conf, diff, all\n",
    "RNN_HIDDEN = 64\n",
    "N_FILTER = 16\n",
    "FILTER_SIZE = 3\n",
    "N_STRIDE = 1\n",
    "LR = 0.001\n",
    "\n",
    "# Load data\n",
    "data = BuildDataLoader(SOURCE, DATA_PATH, NUM_FLAG, EMBED_FLAG)\n",
    "data.shuffle(8)\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "print (\"=== data setup ===\")\n",
    "print (\"pretrain  : {}\".format(len(pretrain_agt_list)))\n",
    "print (\"candidate : {}\".format(len(candidate_list)))\n",
    "print (\"validation: {}\".format(len(validation_list)))\n",
    "print (\"test      : {}\".format(len(test_list)))\n",
    "sim_weight = np.zeros((len(candidate_list), len(test_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic size\n",
    "crf = CrfModel(data, FEAT)\n",
    "# crf.add_instances(data.sequence[:1])\n",
    "# crf.train()\n",
    "# entropy_list, entropy_sum = crf.compute_entropy(data.sequence[0])\n",
    "# print (entropy_list)\n",
    "marginal_h = crf.get_label_size()\n",
    "lens = []\n",
    "for seq in data.sequence:\n",
    "    lens.append(len(seq[0]))\n",
    "max_len = max(lens)\n",
    "input_size = data.get_embed_size()\n",
    "print (\"CNN (row, column)=({}, {})\".format(marginal_h, max_len))\n",
    "print (\"RNN input={}\".format(input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DQN\n",
    "policy_net = DQNtrellis(marginal_h, max_len, input_size, RNN_HIDDEN).to(device)\n",
    "# target_net = DQN(para_h, para_w, input_size, RNN_HIDDEN, N_FILTER, FILTER_SIZE, N_STRIDE).to(device)\n",
    "target_net = copy.deepcopy(policy_net)\n",
    "para_size = sum(p.numel() for p in policy_net.parameters() if p.requires_grad)\n",
    "print ('DQN parameter size: {}'.format(para_size))\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "memory = ReplayMemory(50)\n",
    "\n",
    "steps_done = 0\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain the agent\n",
    "try:\n",
    "    with tqdm(range(50)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            # Initialize the environment and state\n",
    "            pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "            crf.reset()\n",
    "            pretrain_idx = random.sample(range(len(pretrain_agt_list)), CRF_PRETRAIN_SIZE)\n",
    "            crf.add_instances([pretrain_agt_list[i] for i in pretrain_idx])\n",
    "            crf.train()\n",
    "\n",
    "            old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "\n",
    "            # Reduce actions\n",
    "            pretrain_agt_list = [pretrain_agt_list[i] for i in range(len(pretrain_agt_list)) if i not in pretrain_idx]\n",
    "\n",
    "            while len(pretrain_agt_list) > 1:\n",
    "                # Select and perform an action\n",
    "                _, query_idx, _ = select_action(crf, pretrain_agt_list, GREEDY)\n",
    "                query_instance = pretrain_agt_list.pop(query_idx)\n",
    "                action = data.seqs2Tensor(query_instance)\n",
    "                state = crf.get_marginals(query_instance)\n",
    "\n",
    "                # Env (CRF) give reward\n",
    "                crf.add_instances([query_instance])\n",
    "                crf.train()\n",
    "\n",
    "                cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                reward = cur_reward - old_reward\n",
    "                old_reward = cur_reward\n",
    "                reward = torch.tensor([reward], device=device)\n",
    "\n",
    "                # Observe new state\n",
    "                (next_id, next_value) = next_state_action(crf, pretrain_agt_list)\n",
    "\n",
    "                # Store the transition in memory\n",
    "                if len(pretrain_agt_list) == 0: print (\"Warning!\")\n",
    "                memory.push(state, action, next_value, reward, [seq for seq in pretrain_agt_list])\n",
    "\n",
    "                # Move to the next state\n",
    "                state = crf.get_marginals(pretrain_agt_list[next_id])\n",
    "\n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                optimize_model()\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "        #         target_net.load_state_dict(policy_net.state_dict())\n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Pretrain Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "crf.reset()\n",
    "crf.add_instances(pretrain_agt_list)\n",
    "crf.train()\n",
    "ground_list = pretrain_agt_list\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list])\n",
    "count = len(pretrain_agt_list)\n",
    "cost_list = [count]\n",
    "\n",
    "_, _, _, acc = crf.evaluate_acc(test_list)\n",
    "acc_list = [acc]\n",
    "_, _, _, acc_valid = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]\n",
    "print (acc)\n",
    "\n",
    "qvalue_list = []\n",
    "action_mark_list = []\n",
    "prob_list = []\n",
    "seq_list = []\n",
    "seqsq_list = []\n",
    "seqsr_list = []\n",
    "steps_done = 0\n",
    "try:\n",
    "    with tqdm(range(CANDIDATE_SIZE)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            if cost_list[-1] > BUDGET:\n",
    "                break\n",
    "\n",
    "            state = crf.get_parameters()\n",
    "\n",
    "            # Select and perform an action\n",
    "            act_mrk, query_idx, qvalue = select_action(crf, candidate_list, GREEDY)\n",
    "            query_instance = candidate_list.pop(query_idx)\n",
    "\n",
    "            qvalue_list.append(qvalue.item())\n",
    "            action_mark_list.append(act_mrk)\n",
    "            prob_list.append(crf.compute_entropy(query_instance)[-1]/len(query_instance[0]))\n",
    "            if act_mrk == 0:\n",
    "                seqsr_list.append(query_instance)\n",
    "            else:\n",
    "                seqsq_list.append(query_instance)\n",
    "            seq_list.append(query_instance)\n",
    "\n",
    "            # Initialize the environment and state\n",
    "            ground_list = ground_list + [query_instance]\n",
    "\n",
    "            if LOOP_CANDI == 0:\n",
    "                comb = combinations(range(len(ground_list)), 3) \n",
    "            else:\n",
    "                comb = []\n",
    "                if i_episode % 10 == 0:\n",
    "                    LOOP_SIZE += 10\n",
    "                for i in range(LOOP_SIZE):\n",
    "                    comb.append(tuple(random.sample(range(len(ground_list)), LOOP_CANDI)))\n",
    "            \n",
    "            for c_idx in comb:\n",
    "                tmp_candi_list = [ground_list[i] for i in c_idx]\n",
    "                tmp_train_list = [ground_list[i] for i in range(len(ground_list)) if i not in c_idx]\n",
    "                \n",
    "                crf.reset()\n",
    "                crf.add_instances(tmp_train_list)\n",
    "                crf.train()\n",
    "\n",
    "                old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "\n",
    "                while len(tmp_candi_list) > 1:\n",
    "                    _, tmp_query_idx, _ = select_action(crf, tmp_candi_list, GREEDY)\n",
    "                    query_instance = tmp_candi_list.pop(tmp_query_idx)\n",
    "\n",
    "                    crf.add_instances([query_instance])\n",
    "                    crf.train()\n",
    "\n",
    "                    cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                    reward = cur_reward - old_reward\n",
    "                    old_reward = cur_reward\n",
    "\n",
    "                    # Observe new state\n",
    "                    action = data.seqs2Tensor(query_instance)\n",
    "                    state = crf.get_marginals(query_instance)\n",
    "                    reward = torch.tensor([reward], device=device)\n",
    "                    (next_id, next_value) = next_state_action(crf, tmp_candi_list)\n",
    "\n",
    "                    # Store the transition in memory\n",
    "                    memory.push(state, action, next_value, reward, [seq for seq in tmp_candi_list])\n",
    "\n",
    "                    # Move to the next state\n",
    "                    state = crf.get_marginals(pretrain_agt_list[next_id])\n",
    "\n",
    "                    # Perform one step of the optimization (on the target network)\n",
    "                    optimize_model()\n",
    "                # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "            #       target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            crf.reset()\n",
    "            crf.add_instances(ground_list)\n",
    "            crf.train()\n",
    "            \n",
    "            count += 1\n",
    "            cost_list.append(count)\n",
    "            \n",
    "            _, _, _, acc= crf.evaluate_acc(test_list)\n",
    "            acc_list.append(acc)\n",
    "            _, _, _, acc_valid= crf.evaluate_acc(validation_list)\n",
    "            acc_valid_list.append(acc_valid)\n",
    "            \n",
    "#             v2t_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'valid2T')\n",
    "#             v2v_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'valid2V')\n",
    "#             t2t_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'test2T')\n",
    "#             t2v_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'test2V')\n",
    "#             print ('valid2T={}, valid={}, test={}, test2V={}'.format(v2t_acc, v2v_acc, t2t_acc, t2v_acc))\n",
    "#             print ('acc={}, acc_valid={}'.format(acc, acc_valid))\n",
    "                      \n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = \"fix\" if FIX_FLAG else \"\"\n",
    "num = \"num\" if NUM_FLAG else \"\"\n",
    "ini = \"testIni\" if not INITIAL_FLAG else \"\"\n",
    "emb = \"embed\" if EMBED_FLAG else \"\"\n",
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + num + emb + \"_\" + str(VALIDATE_SIZE) + ini + \"_\" + str(BUDGET) + \"budget_\" + TRANS + METHOD + fix + \"_\" + STRATEGY + \"_\" + GREEDY + \"_\" + REWARD\n",
    "filename += \"_\" + str(TARGET_UPDATE) + \"step_\" + str(BATCH_SIZE) + \"batch\" + str(EPS_DECAY) + \"decay_\" + str(LOOP_SIZE) + \"loop_\"\n",
    "filename += \"_\" + str(RNN_HIDDEN) + \"rnn_\" + str(N_FILTER) + \"filter_\" + str(FILTER_SIZE) + \"size_\" + str(N_STRIDE) + \"stride\"\n",
    "\n",
    "with open(filename + \".bin\", \"wb\") as result:\n",
    "    pickle.dump((cost_list, acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(errseq_list):\n",
    "    print ('----- step {} -----'.format(i))\n",
    "    for seq in seqs:\n",
    "        print (\"\".join(str(char) for char in seq[0]))\n",
    "        print (\", \".join(str(char) for char in seq[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(qvalue_list))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].plot(x, qvalue_list, color='0.5')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 1:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l1 = ax[0].scatter(x2, y2, color='r', marker='o')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 0:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l2 = ax[0].scatter(x2, y2, color='g', marker='x')\n",
    "ax[0].legend((l1,l2),\n",
    "           ('$action > \\\\epsilon$', '$action < \\\\epsilon$'))\n",
    "\n",
    "ax[0].set_title('SOD dataset with {} pretraining samples'.format(AGENT_PRETRAIN_SIZE))\n",
    "# plt.xlim(0, 20)\n",
    "ax[0].set_ylabel('Q value')\n",
    "ax[0].set_xlabel('Sequence number')\n",
    "\n",
    "# print (qvalue_list)\n",
    "ax[1].scatter(qvalue_list, prob_list)\n",
    "for i in range(len(qvalue_list)):\n",
    "    ax[1].annotate(i, (qvalue_list[i], prob_list[i]))\n",
    "ax[1].set_xlabel('Q value')\n",
    "ax[1].set_ylabel('Likelihood')\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "fig.set_size_inches(15,5)\n",
    "# plt.show()\n",
    "plt.savefig(filename + '_check.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sim beta\n",
    "with open(\"./results/sod15_200_acc2_fully_none.bin\", \"rb\") as in_file:\n",
    "    (cost_1, _, _, all_acc_1, acc_valid_1) = pickle.load(in_file)\n",
    "#     (cost_1, all_acc_1, acc_valid_1) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod15num_200_75budget_test2TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_2, all_acc_2, acc_valid_2) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod15num_200_75budget_valid2VRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_3, all_acc_3, acc_valid_3) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod15num_200_75budget_valid3TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_4, all_acc_4, acc_valid_4) = pickle.load(in_file)\n",
    "    \n",
    "# with open(\"./results/sod15num_200_75budget_test3TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_5, all_acc_5, acc_valid_5) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_75budget_valid3VRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_6, all_acc_6, acc_valid_6) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_75budget_valid3TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_7, all_acc_7, acc_valid_7) = pickle.load(in_file)\n",
    "\n",
    "plt.plot(cost_1, all_acc_1,\n",
    "         cost_2, all_acc_2,\n",
    "         cost_3, all_acc_3,\n",
    "         cost_4, all_acc_4,)\n",
    "#          cost_5, all_acc_5,\n",
    "#          cost_6, all_acc_6,\n",
    "#          cost_7, all_acc_7)\n",
    "plt.legend(['TE', 'test2T', 'valid2V', 'valid2T', 'test2T-2' ,'valid2V-2', 'valid3T-3'], loc='upper left', fancybox=True, fontsize = 9)\n",
    "# plt.xlim(200, 600)\n",
    "\n",
    "plt.title('EBU dataset with 15 pretraining samples')\n",
    "plt.xlabel('Number of training sequences')\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.savefig('./results/sod.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "SUBSEQ_FLAG = False\n",
    "SUBSEQ_SIZE = 8\n",
    "STRATEGY = 'fully'\n",
    "BETA = 3.0\n",
    "METHOD = 'random' #selfSim, testSim\n",
    "\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "crf = CrfModel(data, FEAT)\n",
    "crf.add_instances(pretrain_agt_list)\n",
    "crf.train()\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list]) \n",
    "count = len(pretrain_agt_list)\n",
    "cost_list = [count]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "\n",
    "in_acc_list = [in_acc]\n",
    "out_acc_list = [out_acc]\n",
    "all_acc_list = [acc]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized and clustered test set.\n",
    "Xs = [seq[0] for seq in test_list]\n",
    "Xs.extend([seq[0] for seq in candidate_list])\n",
    "vec, _ = string_vectorize(Xs)\n",
    "validation_vec = vec[:len(test_list)].tolist()\n",
    "candidate_vec = vec[len(test_list):].tolist()\n",
    "\n",
    "print (len(validation_vec))\n",
    "print (len(candidate_vec))\n",
    "# Pre-calculate similarity: both between validation-test and validation-validate\n",
    "sim_matrix_test = np.zeros((len(candidate_vec), len(validation_vec)))\n",
    "sim_matrix_self = np.zeros((len(candidate_vec), len(candidate_vec)))\n",
    "if METHOD != 'none' and METHOD != 'random':\n",
    "    iterator = tqdm(range(len(candidate_vec)))\n",
    "    for i in iterator:\n",
    "        for j in range(len(validation_vec)):\n",
    "            sim_matrix_test[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], validation_vec[j])\n",
    "        for j in range(len(candidate_vec)):\n",
    "            sim_matrix_self[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], candidate_vec[j])\n",
    "    iterator.close()\n",
    "print ('Similarity done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visited_candidate_idx = []\n",
    "seqs_list = []\n",
    "iterator = tqdm(range(CANDIDATE_SIZE))\n",
    "for seqs_size in iterator:\n",
    "    if cost_list[-1] > BUDGET:\n",
    "        break\n",
    "    \n",
    "    # Sort the test set based on confidence.\n",
    "    prob_test_list = []\n",
    "    for i in range(len(test_list)):\n",
    "        (prob_per_token, _, prob_sum) = crf.compute_confidence(test_list[i])\n",
    "        prob_test_list.append(prob_sum)\n",
    "    rank_idx_test = np.argsort(np.array(prob_test_list), kind='mergesort').tolist()[::-1]\n",
    "\n",
    "    # Calculate the average similarity between the unlabeled samples and the selected test samples.\n",
    "    distance = []\n",
    "    if METHOD == 'testSim':\n",
    "        distance = np.sum(sim_matrix_test[:, rank_idx_test[:M]], axis=1) / M\n",
    "    elif METHOD == 'selfSim':\n",
    "        distance = np.sum(sim_matrix_self, axis=1) / (len(candidate_vec)-1)\n",
    "        \n",
    "\n",
    "    ####\n",
    "    # Compute the top-K tokens and its seq_idx: subsequence with or without SEBSEQ_FLAG\n",
    "    prob_list = []\n",
    "    subseq_idx_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        (prob_per_token, prob_sum) = crf.compute_entropy(candidate_list[i])\n",
    "        prob_sum /= len(candidate_list[i][1])\n",
    "        if STRATEGY == 'partial':\n",
    "            subseq_idxs = []\n",
    "            subseq_prob_sum = -sys.maxsize\n",
    "            if SUBSEQ_FLAG:\n",
    "                end_p = len(prob_per_token) - SUBSEQ_SIZE + 1\n",
    "                for k in range(0, end_p): # the largest subsequence\n",
    "                    prob_tmp = sum([prob_per_token[k+j] for j in range(SUBSEQ_SIZE)]) / SUBSEQ_SIZE\n",
    "                    if prob_tmp > subseq_prob_sum:\n",
    "                        subseq_prob_sum = prob_tmp\n",
    "                        subseq_idxs = [k+j for j in range(SUBSEQ_SIZE)]\n",
    "                if end_p < 1: # if length is not longer than subseq_size\n",
    "                    subseq_prob_sum = prob_sum / len(prob_per_token)\n",
    "                    subseq_idxs = range(0, len(prob_per_token))\n",
    "            else:\n",
    "                token_sorted = np.argsort(np.array(prob_per_token), kind='mergesort').tolist()[::-1]\n",
    "                subseq_idxs = [token_sorted[k] for k in range(min(SUBSEQ_SIZE, len(prob_per_token)))]\n",
    "                subseq_prob_sum = sum([prob_per_token[k] for k in subseq_idxs]) / len(subseq_idxs)\n",
    "            prob_sum = subseq_prob_sum\n",
    "            subseq_idx_list.append(subseq_idxs)\n",
    "\n",
    "        prob_list.append(prob_sum)\n",
    "    \n",
    "    # Entropy weighted with or without similarity\n",
    "    mean_prob = np.mean(prob_list)\n",
    "    std_prob = np.std(prob_list)\n",
    "    prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(candidate_list))]\n",
    "\n",
    "    # norm_dist = [1/(1+math.exp(x)) for x in norm_dist]\n",
    "    score_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        if METHOD == 'none':\n",
    "            score_list.append(prob_list[i])\n",
    "        elif METHOD != 'random':\n",
    "            score_list.append(prob_list[i] * math.pow(distance[i], BETA))\n",
    "    \n",
    "    # Locate the subseq_idx with largest score\n",
    "    rank_idx = np.argsort(np.array(score_list), kind='mergesort').tolist()[::-1]\n",
    "    if METHOD == 'random':\n",
    "        rand_idx = random.shuffle(list(range(len(score_list))))\n",
    "        \n",
    "    for i in rank_idx:\n",
    "        if i not in visited_candidate_idx:\n",
    "            seq_idx = i\n",
    "            visited_candidate_idx.append(seq_idx)\n",
    "            break\n",
    "    query_seq = candidate_list[seq_idx]\n",
    "    \n",
    "    if STRATEGY == 'partial':\n",
    "        subseq_idxs = subseq_idx_list[seq_idx]\n",
    "        predict_y = crf.predict(query_seq)\n",
    "        for i in range(len(query_seq[1])):\n",
    "            if i not in subseq_idxs:\n",
    "                query_seq[1][i] = predict_y[i]\n",
    "        count += len(subseq_idxs)\n",
    "    else:\n",
    "#         count += len(query_seq[1])\n",
    "        count += 1\n",
    "    cost_list.append(count)\n",
    "    \n",
    "    crf.add_instances([query_seq])\n",
    "    seqs_list.append(query_seq)\n",
    "    crf.train()\n",
    "    (in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "    in_acc_list.append(in_acc)\n",
    "    out_acc_list.append(out_acc)\n",
    "    all_acc_list.append(acc)\n",
    "    \n",
    "    (in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "    acc_valid_list.append(acc_valid)\n",
    "iterator.close()\n",
    "print ('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + \"_\" + str(VALIDATE_SIZE) + \"_\" + str(BUDGET) + \"budget_\" + STRATEGY + \"_\" + METHOD \n",
    "if STRATEGY == 'partial':\n",
    "    filename += \"_sub\" + str(SUBSEQ_SIZE) + str(SUBSEQ_FLAG)\n",
    "if METHOD != 'none' and METHOD != 'random':\n",
    "    filename += \"_beta\" + str(BETA)\n",
    "    if METHOD == 'testSim':\n",
    "        filename += \"_M\" + str(M)\n",
    "filename += \".bin\"\n",
    "\n",
    "with open(filename, \"wb\") as result:\n",
    "    pickle.dump((cost_list, in_acc_list, out_acc_list, all_acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_q = gen_dataDistr(seqsq_list + pretrain_agt_list)\n",
    "rand_q = gen_dataDistr(seqsr_list + pretrain_agt_list)\n",
    "print (\"selected set has {} formats\".format(len(select_q)))\n",
    "print (\"rand set has {} formats\".format(len(rand_q)))\n",
    "\n",
    "# for rank, key in enumerate(sorted(uniques, key=uniques.get, reverse=True), 1):\n",
    "#     print (rank, key)\n",
    "\n",
    "data_dict = add_dataformat({}, test_list)\n",
    "data_dict = add_dataformat(data_dict, validation_list)\n",
    "data_dict = add_dataformat(data_dict, seqsq_list + seqsr_list + pretrain_agt_list)\n",
    "data_dict = add_dataformat(data_dict, candidate_list)\n",
    "print (\"{} formats overall\".format(len(data_dict)))\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    print (\"{}: {}\".format(key, str(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_ratio = len(set.intersection(set(test_q.keys()),set(select_q.keys()))) / len(test_q)\n",
    "print (\"select & test / test: {}\".format(select_test_ratio))\n",
    "\n",
    "select_valid_ratio = len(set.intersection(set(valid_q.keys()),set(select_q.keys()))) / len(valid_q)\n",
    "print (\"select & valid / valid: {}\".format(select_valid_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "for key, value in test_q.items():\n",
    "    x1.append(data_dict[key])\n",
    "    y1.append(value)\n",
    "l1 = plt.bar(x1, y1)\n",
    "\n",
    "x2 = []\n",
    "y2 = []\n",
    "for key, value in valid_q.items():\n",
    "    x2.append(data_dict[key])\n",
    "    y2.append(value)\n",
    "l2 = plt.bar(x2, y2)\n",
    "\n",
    "x3 = []\n",
    "y3 = []\n",
    "for key, value in select_q.items():\n",
    "    x3.append(data_dict[key])\n",
    "    y3.append(value)\n",
    "l3 = plt.bar(x3, y3)\n",
    "\n",
    "x4 = []\n",
    "y4 = []\n",
    "for key, value in rand_q.items():\n",
    "    x4.append(data_dict[key])\n",
    "    y4.append(value)\n",
    "l4 = plt.bar(x4, y4)\n",
    "\n",
    "plt.title('data distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.legend((l1, l2, l3, l4), ('test', 'validation', 'select', 'rand'))\n",
    "# plt.show()\n",
    "\n",
    "# x4 = []\n",
    "# y4 = []\n",
    "# for key, value in candidate_q.items():\n",
    "#     x4.append(data_dict[key])\n",
    "#     y4.append(value)\n",
    "# plt.bar(x4, y4)\n",
    "# plt.title('candidate distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.savefig(filename + '_distr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results1/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/sod1000_fully_selfSim_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod_partial_selfSim_sub8False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod1000_partial_selfSim_sub8False_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_self_part, in_acc_self_part, out_acc_self_part, all_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_test_part, in_acc_test_part, out_acc_test_part, all_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='serif')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, linestyle='--')\n",
    "ax[0].plot(cost_9, all_acc_9)\n",
    "ax[0].plot(cost_11, all_acc_11)\n",
    "ax[0].plot(cost_self_part, all_acc_self_part)\n",
    "ax[0].plot(cost_test_part, all_acc_test_part, c='black')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results1/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/sdh_fully_selfSim_beta1.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh_partial_selfSim_sub8False_beta0.5_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_self_part, in2_acc_self_part, out_acc_self_part, all2_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh1000_partial_testSim_sub8False_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_test_part, in2_acc_test_part, out_acc_test_part, all2_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, linestyle='--')\n",
    "ax[1].plot(cost2_9, all2_acc_9)\n",
    "ax[1].plot(cost2_11, all2_acc_11)\n",
    "ax[1].plot(cost2_self_part, all2_acc_self_part)\n",
    "ax[1].plot(cost2_test_part, all2_acc_test_part, c='black')\n",
    "ax[1].set_ylim([0.85, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results1/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/ibm1000_partial_testSim_sub13False_beta1.0_M10_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_partial_selfSim_sub17False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_self_part, in3_acc_self_part, out_acc_self_part, all3_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_test_part, in3_acc_test_part, out_acc_test_part, all3_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=\":\")\n",
    "ax[2].plot(cost3_8, all3_acc_8, linestyle='--')\n",
    "ax[2].plot(cost3_9, all3_acc_9)\n",
    "ax[2].plot(cost3_11, all3_acc_11)\n",
    "ax[2].plot(cost3_self_part, all3_acc_self_part)\n",
    "ax[2].plot(cost3_test_part, all3_acc_test_part, c='black')\n",
    "ax[2].set_ylim([0.745, 0.924])\n",
    "ax[2].set_xlim([200,1000])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod1000_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod_partial_none_sub12False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='arial')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, c='orange')\n",
    "ax[0].plot(cost_9, all_acc_9, c='green')\n",
    "ax[0].plot(cost_11, all_acc_11, c='red')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['Full', r'w=5', r'w=9', r'w=12'], loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sdh_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh_partial_none_sub14False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, c='orange')\n",
    "ax[1].plot(cost2_9, all2_acc_9, c='green')\n",
    "ax[1].plot(cost2_11, all2_acc_11, c='red')\n",
    "ax[1].set_ylim([0.83, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['Full', 'w=5', 'w=8', 'w=14'],\n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/ibm_partial_none_sub11False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_partial_none_sub7False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=':')\n",
    "ax[2].plot(cost3_8, all3_acc_8, c='orange')\n",
    "ax[2].plot(cost3_9, all3_acc_9, c='green')\n",
    "ax[2].plot(cost3_11, all3_acc_11, c='red')\n",
    "ax[2].set_xlim([200,1000])\n",
    "# ax[2].set_ylim([0.83, 0.978])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['Full', 'w=15', 'w=19', 'w=23'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()\n",
    "# plt.tick_params(labelsize=20)\n",
    "# plt.savefig('perp1.png', bbox_inches='tight')\n",
    "    \n",
    "# plt.plot(cost_f, all_acc_f,\n",
    "#          cost_8, all_acc_8,\n",
    "#          cost_9, all_acc_9,\n",
    "#          cost_11, all_acc_11,\n",
    "#          cost_self_part, all_acc_self_part,\n",
    "#          cost_test_part, all_acc_test_part)\n",
    "# plt.legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], loc='lower right', fancybox=True, fontsize = 12)\n",
    "# # plt.ylim(0.86, 0.97)\n",
    "\n",
    "# plt.title('SOD dataset with 5 pretraining samples')\n",
    "# plt.xlabel('Number of training labels')\n",
    "# plt.ylabel('Prediction accuracy')\n",
    "# plt.savefig('./results/sod.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "ll5fy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
