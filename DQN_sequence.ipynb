{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Cuda: True ===\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable  \n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import re\n",
    "import copy\n",
    "from itertools import combinations \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "import nltk\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"== Cuda: {} ===\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Loader\n",
    "class BuildDataLoader:\n",
    "    \n",
    "    def __init__(self, source, folder, num_flag, embed_flag):\n",
    "        self.sequence = []\n",
    "        self.word_dict = {}\n",
    "        self.label_dict = {}\n",
    "        self.num_flag = num_flag\n",
    "        self.embed_flag = embed_flag\n",
    "        self.folder = folder\n",
    "\n",
    "        if source == 'conll':\n",
    "            with open(folder + \"train.txt\", 'r') as file:\n",
    "                x=[]\n",
    "                y=[]\n",
    "                for line in file:\n",
    "                    tokens = line.replace(\"\\n\",'').split()\n",
    "                    if len(tokens) < 1:\n",
    "                        self.sequence.append((x,y))\n",
    "                        x = []\n",
    "                        y = []\n",
    "                    else:\n",
    "                        char = tokens[0]\n",
    "                        label = tokens[2]\n",
    "                        if self.num_flag and char.replace('.','').isdigit():\n",
    "                            char = 'NUM'\n",
    "                        x.append(char)\n",
    "                        y.append(label)\n",
    "                        if char not in self.word_dict:\n",
    "                            self.word_dict[char] = len(self.word_dict)\n",
    "                        if label not in self.label_dict:\n",
    "                            self.label_dict[label] = len(self.label_dict)\n",
    "        else:\n",
    "            with open(folder + '_string.txt', 'r') as x_file, open(folder + '_label.txt', 'r') as y_file: \n",
    "                for x, y in zip(x_file, y_file):\n",
    "                    x = [char for char in x.replace(\"\\n\",'')]\n",
    "                    y = y.replace(\"\\n\",'').split(',')\n",
    "                    if(len(y) > 1):\n",
    "                        if len(y[-1]) == 0:\n",
    "                            y = y[:-1]\n",
    "                        if self.num_flag:\n",
    "                            for i in range(len(x)):\n",
    "                                if x[i].isdigit():\n",
    "                                    x[i] = 'x'\n",
    "                        for char, label in zip(x, y):\n",
    "                            if char not in self.word_dict:\n",
    "                                self.word_dict[char] = len(self.word_dict)\n",
    "                            if label not in self.label_dict:\n",
    "                                self.label_dict[label] = len(self.label_dict)\n",
    "                        self.sequence.append((x, y))\n",
    "    \n",
    "    def shuffle(self, seed = 4):\n",
    "        random.Random(4).shuffle(self.sequence)\n",
    "    \n",
    "    def seqs2Tensor(self, sequence):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            char_embed = []\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    char_embed.append(wv[char])\n",
    "            tensor = torch.from_numpy(np.array(char_embed)).type(torch.FloatTensor)\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "        else:\n",
    "            tensor = torch.zeros(len(sequence[0]), len(self.word_dict), device=device)\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    tensor[j][self.word_dict[char]] = 1\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    def get_embed_size(self):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            return wv.vector_size\n",
    "        else:\n",
    "            return len(self.word_dict)\n",
    "    \n",
    "    def get_word_dict(self):\n",
    "        return self.word_dict\n",
    "    \n",
    "    def get_label_dict(self):\n",
    "        return self.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF\n",
    "class CrfModel(object):\n",
    "    \n",
    "    def __init__(self, data, feature):\n",
    "        self.label_dict = data.label_dict\n",
    "        self.word_dict = data.word_dict\n",
    "        self.num_flag = data.num_flag\n",
    "        self.feature = feature\n",
    "        \n",
    "        self.crf = CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "        \n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "        print ('label dict size: {}'.format(len(self.label_dict)))\n",
    "        print ('word dict size: {}'.format(len(self.word_dict)))\n",
    "    def reset(self):\n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "    def char2feature(self, sent, i):\n",
    "        # for current character\n",
    "        w = sent[i]\n",
    "        if self.num_flag and w.isdigit():\n",
    "            w = 'x'\n",
    "        features = {'0:word': w}\n",
    "        # for previous character\n",
    "        if i > 0:\n",
    "            w = sent[i-1]\n",
    "            if self.num_flag and w.isdigit():\n",
    "                w = 'x'\n",
    "            features.update({'-1:word': w})\n",
    "        # for next character\n",
    "        if i < len(sent)-1:\n",
    "            w = sent[i+1]\n",
    "            if self.num_flag and w.isdigit():\n",
    "                w = 'x'\n",
    "            features.update({'+1:word': w})\n",
    "        return features\n",
    "    \n",
    "    def add_instances(self, sequences):\n",
    "        for seq in sequences:\n",
    "            x = seq[0]\n",
    "            y = seq[1]\n",
    "            self.X_train.append([self.char2feature(x, i) for i in range(len(x))])\n",
    "            self.Y_train.append(y)\n",
    "    \n",
    "    def compute_confidence(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        y_pred = self.crf.tagger_.tag(x)\n",
    "        prob_norm = math.exp(math.log(self.crf.tagger_.probability(y_pred)) / len(x))\n",
    "        \n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        prob_list = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            prob_list.append(max(marginal_prob))\n",
    "        return (prob_list, sum(prob_list), prob_norm)\n",
    "    \n",
    "    def compute_entropy(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        self.crf.tagger_.set(x)\n",
    "        entropy_seq = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            entropy_seq.append(scipy.stats.entropy(marginal_prob))\n",
    "        return (entropy_seq, sum(entropy_seq))\n",
    "    \n",
    "    def train(self):\n",
    "        self.crf.fit(self.X_train, self.Y_train) \n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def predict(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        return self.crf.tagger_.tag(x)    \n",
    "    \n",
    "    def evaluate_acc(self, sequences):\n",
    "        # Calculate phrase-level accuracy and out-of-phrase accuracy\n",
    "        X_test = [[self.char2feature(seq[0], i) for i in range(len(seq[0]))] for seq in sequences]\n",
    "        Y_test = [seq[1] for seq in sequences]\n",
    "        Y_pred = self.crf.predict(X_test)\n",
    "        \n",
    "        # Consider the accuracy in phrase level.\n",
    "        in_cnt,  in_crt = 0, 0    # Total/correct number of phrases\n",
    "        out_cnt, out_crt = 0, 0   # Total/correct number of \"o\"\n",
    "        all_cnt, all_crt = 0, 0   # Total/correct number of all words\n",
    "\n",
    "        acc = []\n",
    "        for y_test, y_pred in zip(Y_test, Y_pred):\n",
    "            cnt, crt = 0, 0\n",
    "            correct_flag = False\n",
    "            for j in range(len(y_test)):\n",
    "                all_cnt += 1\n",
    "                cnt += 1\n",
    "                if y_test[j] == y_pred[j]:\n",
    "                    all_crt += 1\n",
    "                    crt += 1\n",
    "\n",
    "                # If the character is a beginning-of-phrase.\n",
    "                if y_test[j][0] == 'b' or y_test[j][0] == 'B':\n",
    "                    in_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                        correct_flag = True\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an inside-of-phrase.\n",
    "                elif y_test[j][0] == 'i' or y_test[j][0] == 'I':\n",
    "                    if y_test[j] != y_pred[j]:\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an out-of-phrase.\n",
    "                elif y_test[j][0] == 'o' or y_test[j][0] == 'O':\n",
    "                    out_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        out_crt += 1\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                            correct_flag = False\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                            correct_flag = False\n",
    "\n",
    "            acc.append(crt/cnt)\n",
    "            # For the case where the phrase is at the end of a string.\n",
    "            if correct_flag:\n",
    "                in_crt += 1\n",
    "        in_acc = 0 if in_cnt == 0 else in_crt/in_cnt\n",
    "        out_acc = 0 if out_cnt == 0 else out_crt/out_cnt\n",
    "        all_acc = 0 if all_cnt == 0 else all_crt/all_cnt \n",
    "            \n",
    "        return in_acc, out_acc, all_acc, sum(acc)/len(acc)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        loc = {'0':0, '-1':1, '+1':2}\n",
    "        if self.feature == 'all':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict) + len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = len(loc) * len(self.word_dict) + self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "        elif self.feature == 'node':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "        else:\n",
    "            paras = torch.zeros(len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "                \n",
    "        paras = paras.unsqueeze(0).unsqueeze(0).to(device) # batch, channel, w, h\n",
    "        return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a set of string by n-grams.\n",
    "def string_vectorize(Xs_list):\n",
    "    vc = CV(analyzer='char_wb', ngram_range=(3, 4), min_df=1, token_pattern='[a-z]{2,}')\n",
    "    name = []\n",
    "    for i in Xs_list:\n",
    "        s = re.findall('(?i)[a-z]{2,}', \"\".join(str(x) for x in i))\n",
    "        name.append(' '.join(s))\n",
    "    vc.fit(name)\n",
    "    vec = vc.transform(name).toarray()\n",
    "    # print(name)\n",
    "    # print(vec)\n",
    "    dictionary = vc.get_feature_names()\n",
    "    return vec, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer: a cyclic buffer of bounded size that holds the transitions observed recently\n",
    "Transition = namedtuple('Transition',\n",
    "                       ('state', 'action', 'next_state', 'reward', 'sequences'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network\n",
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, para_h, para_w, w_dim, rnn_hidden, n_filters, filter_size, n_stride):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # CNN for CRF parameters\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=n_filters,   \n",
    "                kernel_size=filter_size,              \n",
    "                stride=n_stride,        \n",
    "            )\n",
    "        self.bn1 = nn.BatchNorm2d(n_filters)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters*2, filter_size, n_stride)\n",
    "        self.bn2 = nn.BatchNorm2d(n_filters*2)\n",
    "        self.conv3 = nn.Conv2d(n_filters*2, n_filters*2, filter_size, n_stride)\n",
    "        self.bn3 = nn.BatchNorm2d(n_filters*2)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = filter_size, stride = n_stride):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(para_w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(para_h)))\n",
    "        linear_input_size = convw * convh * n_filters * 2\n",
    "        \n",
    "        self.fc1 = nn.Linear(linear_input_size, rnn_hidden)\n",
    "        \n",
    "        # LSTM for w sequence\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=w_dim,\n",
    "            hidden_size=rnn_hidden, \n",
    "            num_layers=1,\n",
    "            batch_first=True,  # input＆output (batch，time_step，input_size)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(2 * rnn_hidden, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, crf_x, seq_x):\n",
    "        # CNN\n",
    "        x1 = F.relu(self.bn1(self.conv1(crf_x)))\n",
    "        x1 = F.relu(self.bn2(self.conv2(x1)))\n",
    "        x1 = F.relu(self.bn3(self.conv3(x1)))\n",
    "        x1 = F.relu(self.fc1(x1.view(x1.size(0), -1)))\n",
    "        \n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size) \n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out,_ = self.rnn(seq_x, None) \n",
    "        # output of last time step\n",
    "#         rnn_out = self.out(r_out[:, -1, :])\n",
    "        x2 = r_out[:, -1, :]\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        return self.fc(x) # flatten the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, sequences, greedy_select):\n",
    "    max_idx = 0\n",
    "    \n",
    "    if greedy_select == 'te':\n",
    "        prob_list = []\n",
    "        for seq in sequences:\n",
    "            (prob_per_token, prob_sum) = crf.compute_entropy(seq)\n",
    "            prob_list.append(prob_sum/len(seq[1]))\n",
    "        # normalize\n",
    "        mean_prob = np.mean(prob_list)\n",
    "        std_prob = np.std(prob_list)\n",
    "        prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(sequences))]\n",
    "        max_idx = np.argsort(np.array(prob_list), kind='mergesort').tolist()[::-1][0]\n",
    "    \n",
    "    max_q_value = policy_net(state, data.seqs2Tensor(sequences[max_idx]))\n",
    "\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = 0.3\n",
    "#     eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "#         math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \n",
    "    if sample < eps_threshold:\n",
    "        return (0, max_idx, max_q_value)\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "#         q_value = policy_net(get_state_action(seq, state))\n",
    "        q_value = policy_net(state, data.seqs2Tensor(seq))\n",
    "        if max_q_value < q_value:\n",
    "            max_q_value = q_value\n",
    "            max_idx = i\n",
    "    return (1, max_idx, max_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(crf, validation_list, test_list, sim_weight, trans_flag):\n",
    "    if trans_flag == 'test3T' or trans_flag == 'test2T':\n",
    "        source_seqs = test_list\n",
    "        target_seqs = test_list\n",
    "    elif trans_flag == 'valid3V' or trans_flag == 'valid2V':\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = validation_list\n",
    "    else:\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = test_list\n",
    "\n",
    "    source_q = gen_dataDistr(source_seqs)\n",
    "    target_q = gen_dataDistr(target_seqs)\n",
    "    acc_reweight = []\n",
    "    idx = []\n",
    "    for i, seq in enumerate(source_seqs):\n",
    "        _, _, _, acc = crf.evaluate_acc([seq])\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        ratio_source = source_q[x] / len(source_seqs)\n",
    "        if trans_flag == 'kmers':\n",
    "            acc_reweight.append(sim_weight[i] * acc)\n",
    "            idx.append(i)\n",
    "        elif x in target_q:\n",
    "            ratio_target = target_q[x] / len(target_seqs)\n",
    "            if trans_flag == 'test2T' or trans_flag == 'valid2V' or trans_flag == 'valid2T':\n",
    "                acc_reweight.append(acc)\n",
    "                idx.append(i)\n",
    "            elif trans_flag == 'test3T' or trans_flag == 'valid3V':\n",
    "                acc_reweight.append(ratio_target * acc)\n",
    "                idx.append(i)\n",
    "            else:\n",
    "                acc_reweight.append(ratio_target/ratio_source * acc)\n",
    "                idx.append(ratio_target/ratio_source)\n",
    "            \n",
    "    minidx = np.argsort(acc_reweight)\n",
    "#     errseq = [source_seqs[idx[i]] for i in minidx[:10]]\n",
    "    errseq = []\n",
    "    pred = [crf.predict(err) for err in errseq]\n",
    "    acc = sum(acc_reweight) / sum(idx)\n",
    "    return (acc, errseq, pred)\n",
    " \n",
    "    # confidence on test set\n",
    "#     conf = 0\n",
    "#     for seq in test_list:\n",
    "#         conf += crf.compute_entropy(seq)[-1]/len(seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    \n",
    "#     state_batch = []\n",
    "#     for i in range(len(batch.state)):\n",
    "#         state_actions.append(get_state_action(batch.action[i], batch.state[i]))\n",
    "    \n",
    "    state_batch  = torch.cat(batch.state)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    # padding sequences\n",
    "    seq_lengths = []\n",
    "    embed_dim = 0\n",
    "    batch_size = 0\n",
    "    for a in batch.action:\n",
    "        seq_lengths.append(a.shape[1])\n",
    "        embed_dim = a.shape[2]\n",
    "        batch_size += 1\n",
    "    max_len = max(seq_lengths)\n",
    "    action_batch = torch.zeros((batch_size, max_len, embed_dim), device=device)\n",
    "    for i, a in enumerate(batch.action):\n",
    "        a = a.squeeze(0)\n",
    "        if a.shape[0] < max_len:\n",
    "            padding = torch.zeros((max_len - a.shape[0], embed_dim), device=device)\n",
    "            a = torch.cat([a, padding])\n",
    "        action_batch[i] = a\n",
    "#     action_batch = torch.nn.utils.rnn.pack_padded_sequence(actions, seq_lengths, batch_first=True, enforce_sorted=False)  \n",
    "\n",
    "    next_states = [s for s in batch.next_state if s is not None]\n",
    "    next_state_actions = []\n",
    "    next_reward = []\n",
    "    for i in range(len(next_states)):\n",
    "        next_s = next_states[i]\n",
    "        max_q_value = -sys.maxsize - 1\n",
    "        max_idx = 0\n",
    "        for seq in batch.sequences[i]:\n",
    "#             q_value = target_net(get_state_action(seq, next_s))\n",
    "            q_value = target_net(next_s, data.seqs2Tensor(seq))\n",
    "            if max_q_value < q_value:\n",
    "                max_q_value = q_value\n",
    "                max_idx = i\n",
    "        next_reward.append(max_q_value)\n",
    "    \n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = torch.cat(next_reward).squeeze(1)\n",
    "#     print (non_final_mask)\n",
    "#     print (next_reward)\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    policy_net.train()\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== data setup ===\n",
      "pretrain  : 15\n",
      "candidate : 600\n",
      "validation: 200\n",
      "test      : 200\n"
     ]
    }
   ],
   "source": [
    "# Train Q-function\n",
    "BATCH_SIZE = 5\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 20\n",
    "TARGET_UPDATE = 20\n",
    "\n",
    "SOURCE = 'ebu'\n",
    "METHOD = 'RL'\n",
    "if SOURCE == 'conll':\n",
    "    DATA_PATH = \"./datasets/conll2000/\" + SOURCE\n",
    "else:\n",
    "    DATA_PATH = \"./datasets/building/\" + SOURCE\n",
    "CRF_PRETRAIN_SIZE = 5\n",
    "AGENT_PRETRAIN_SIZE = 15\n",
    "CANDIDATE_SIZE = 600\n",
    "VALIDATE_SIZE = 200\n",
    "TEST_SIZE = 200\n",
    "BUDGET = 75\n",
    "FEAT = 'all' # all or node or edge\n",
    "GREEDY = 'te' # rand or te\n",
    "FIX_FLAG = False\n",
    "NUM_FLAG = True\n",
    "EMBED_FLAG = True\n",
    "TRANS = 'valid2V' # kmers or valid2V or valid2T or test2V or test2T\n",
    "LOOP_SIZE = 5\n",
    "LOOP_CANDI = 3\n",
    "INITIAL_FLAG = True\n",
    "REWARD = 'acc' # acc, conf, diff, all\n",
    "RNN_HIDDEN = 64\n",
    "N_FILTER = 16\n",
    "FILTER_SIZE = 4\n",
    "N_STRIDE = 2\n",
    "LR = 0.001\n",
    "\n",
    "# Load data\n",
    "data = BuildDataLoader(SOURCE, DATA_PATH, NUM_FLAG, EMBED_FLAG)\n",
    "data.shuffle(8)\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "print (\"=== data setup ===\")\n",
    "print (\"pretrain  : {}\".format(len(pretrain_agt_list)))\n",
    "print (\"candidate : {}\".format(len(candidate_list)))\n",
    "print (\"validation: {}\".format(len(validation_list)))\n",
    "print (\"test      : {}\".format(len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out to PAL's input formats\n",
    "with open('../PAL/datasets/{}.train'.format(SOURCE), 'w') as wfile:\n",
    "    for seq in pretrain_agt_list + candidate_list:\n",
    "        for i in range(len(seq[0])):\n",
    "            wfile.write('{}\\t{}\\n'.format(seq[0][i].replace(' ', '-'), seq[1][i]))\n",
    "        wfile.write('\\n')\n",
    "wfile.close()\n",
    "with open('../PAL/datasets/{}.test'.format(SOURCE), 'w') as wfile:\n",
    "    for seq in test_list:\n",
    "        for i in range(len(seq[0])):\n",
    "            wfile.write('{}\\t{}\\n'.format(seq[0][i].replace(' ', '-'), seq[1][i]))\n",
    "        wfile.write('\\n')\n",
    "wfile.close()\n",
    "with open('../PAL/datasets/{}.dev'.format(SOURCE), 'w') as wfile:\n",
    "    for seq in validation_list:\n",
    "        for i in range(len(seq[0])):\n",
    "            wfile.write('{}\\t{}\\n'.format(seq[0][i].replace(' ', '-'), seq[1][i]))\n",
    "        wfile.write('\\n')\n",
    "wfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weight = np.zeros((len(candidate_list), len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Vectorized and clustered test set.\n",
    "Xs = [seq[0] for seq in test_list]\n",
    "Xs.extend([seq[0] for seq in candidate_list])\n",
    "vec, _ = string_vectorize(Xs)\n",
    "test_vec = vec[:len(test_list)].tolist()\n",
    "candidate_vec = vec[len(test_list):].tolist()\n",
    "print (\"candidate size: \" + str(len(candidate_vec)))\n",
    "print (\"validate size: \" + str(len(test_vec)))\n",
    "\n",
    "# Pre-calculate similarity: both between validation-test and validation-validate\n",
    "sim_matrix_test = np.zeros((len(candidate_vec), len(test_vec)))\n",
    "try:\n",
    "    with tqdm(range(len(candidate_vec))) as iterator:\n",
    "        for i in iterator:\n",
    "            for j in range(len(test_vec)):\n",
    "                # cosine distance is 1-cosine(a,b)\n",
    "                sim_matrix_test[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], test_vec[j])\n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "sim_weight = softmax(np.sum(sim_matrix_test, axis=1) / sim_matrix_test.shape[1])\n",
    "print ('Similarity done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 33 formats\n",
      "validation set has 44 formats\n",
      "candidate set has 80 formats\n",
      "valid & test / test: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# generate data distribution\n",
    "def gen_dataDistr(sequences):\n",
    "    data_q = {}\n",
    "    for seq in sequences:\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        if x not in data_q:\n",
    "            data_q[x] = 1\n",
    "        else:\n",
    "            data_q[x] += 1\n",
    "    return data_q\n",
    "\n",
    "def add_dataformat(data_dict, sequences):\n",
    "    for seq in sequences:\n",
    "        x = \"\".join(str(char) for char in seq[0])\n",
    "        if x not in data_dict:\n",
    "            data_dict[x] = len(data_dict)\n",
    "    return data_dict\n",
    "        \n",
    "# Check the overlapping of data format\n",
    "test_q = gen_dataDistr(test_list)\n",
    "print (\"test set has {} formats\".format(len(test_q)))\n",
    "\n",
    "valid_q = gen_dataDistr(validation_list)\n",
    "print (\"validation set has {} formats\".format(len(valid_q)))\n",
    "\n",
    "candidate_q = gen_dataDistr(candidate_list)\n",
    "print (\"candidate set has {} formats\".format(len(candidate_q)))\n",
    "\n",
    "valid_test_ratio = len(set.intersection(set(test_q.keys()),set(valid_q.keys()))) / len(test_q)\n",
    "print (\"valid & test / test: {}\".format(valid_test_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label dict size: 126\n",
      "word dict size: 25\n",
      "CNN (row, column)=(201, 126)\n",
      "RNN input=100\n",
      "DQN parameter size: 727217\n"
     ]
    }
   ],
   "source": [
    "# Pretrain CRF\n",
    "crf = CrfModel(data, FEAT)\n",
    "crf.add_instances(pretrain_crf_list)\n",
    "crf.train()\n",
    "\n",
    "_, _, para_h, para_w = crf.get_parameters().size()\n",
    "input_size = data.get_embed_size()\n",
    "print (\"CNN (row, column)=({}, {})\".format(para_h, para_w))\n",
    "print (\"RNN input={}\".format(input_size))\n",
    "\n",
    "# Initialize DQN\n",
    "policy_net = DQN(para_h, para_w, input_size, RNN_HIDDEN, N_FILTER, FILTER_SIZE, N_STRIDE).to(device)\n",
    "# target_net = DQN(para_h, para_w, input_size, RNN_HIDDEN, N_FILTER, FILTER_SIZE, N_STRIDE).to(device)\n",
    "target_net = copy.deepcopy(policy_net)\n",
    "para_size = sum(p.numel() for p in policy_net.parameters() if p.requires_grad)\n",
    "print ('DQN parameter size: {}'.format(para_size))\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "memory = ReplayMemory(50)\n",
    "\n",
    "steps_done = 0\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:07<01:29,  1.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-950e4cbb2a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_agt_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_agt_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGREEDY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mquery_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain_agt_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseqs2Tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-114a9f398800>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state, sequences, greedy_select)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmax_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmax_q_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseqs2Tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-98339719f04a>\u001b[0m in \u001b[0;36mseqs2Tensor\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mnum_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NUM\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flag\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"word2vec\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".kv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mchar_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ll5fy36/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compatible_hash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ll5fy36/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ll5fy36/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ll5fy36/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pretrain the agent\n",
    "try:\n",
    "    with tqdm(range(50)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            # Initialize the environment and state\n",
    "            pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "            crf.reset()\n",
    "            pretrain_idx = random.sample(range(len(pretrain_agt_list)), CRF_PRETRAIN_SIZE)\n",
    "            crf.add_instances([pretrain_agt_list[i] for i in pretrain_idx])\n",
    "            crf.train()\n",
    "\n",
    "            old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "            state = crf.get_parameters()\n",
    "\n",
    "            # Reduce actions\n",
    "            pretrain_agt_list = [pretrain_agt_list[i] for i in range(len(pretrain_agt_list)) if i not in pretrain_idx]\n",
    "\n",
    "            while len(pretrain_agt_list) > 1:\n",
    "                # Select and perform an action\n",
    "                _, query_idx, _ = select_action(state, pretrain_agt_list, GREEDY)\n",
    "                query_instance = pretrain_agt_list.pop(query_idx)\n",
    "                action = data.seqs2Tensor(query_instance)\n",
    "\n",
    "                # Env (CRF) give reward\n",
    "                crf.add_instances([query_instance])\n",
    "                crf.train()\n",
    "\n",
    "                cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                reward = cur_reward - old_reward\n",
    "                old_reward = cur_reward\n",
    "                reward = torch.tensor([reward], device=device)\n",
    "\n",
    "                # Observe new state\n",
    "                next_state = crf.get_parameters()\n",
    "\n",
    "                # Store the transition in memory\n",
    "                if len(pretrain_agt_list) == 0: print (\"Warning!\")\n",
    "                memory.push(state, action, next_state, reward, [seq for seq in pretrain_agt_list])\n",
    "\n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "\n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                optimize_model()\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "        #         target_net.load_state_dict(policy_net.state_dict())\n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Pretrain Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9449999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/600 [00:04<40:14,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.864285714285716, test=22.768571428571423, test2V=0.09031428571428558\n",
      "acc=0.9464285714285713, acc_valid=0.9042857142857141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/600 [00:07<38:57,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.864285714285716, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9042857142857141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/600 [00:13<43:18,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09032142857142857, valid=4.868571428571429, test=22.770357142857137, test2V=0.09032142857142844\n",
      "acc=0.9482142857142856, acc_valid=0.9085714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/600 [00:18<45:59,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09032142857142857, valid=4.868571428571429, test=22.770357142857137, test2V=0.09032142857142844\n",
      "acc=0.9482142857142856, acc_valid=0.9085714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 5/600 [00:23<47:54,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09032142857142857, valid=4.868571428571429, test=22.770357142857137, test2V=0.09032142857142844\n",
      "acc=0.9482142857142856, acc_valid=0.9085714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/600 [00:29<50:04,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.867142857142858, test=22.769642857142852, test2V=0.09031428571428558\n",
      "acc=0.9474999999999997, acc_valid=0.9071428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/600 [00:33<47:51,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.865714285714287, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9057142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 8/600 [00:39<51:03,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.865714285714287, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9057142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/600 [00:45<54:33,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.865714285714287, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9057142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 10/600 [00:52<57:05,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.865714285714287, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9057142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 11/600 [01:01<1:07:30,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09031428571428571, valid=4.864285714285716, test=22.768928571428564, test2V=0.09031428571428558\n",
      "acc=0.946785714285714, acc_valid=0.9042857142857141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 12/600 [01:12<1:17:50,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09032857142857142, valid=4.870000000000001, test=22.77464285714285, test2V=0.09032857142857129\n",
      "acc=0.9510714285714285, acc_valid=0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 13/600 [01:22<1:25:52,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.885714285714287, test=22.782857142857136, test2V=0.090392857142857\n",
      "acc=0.9592857142857141, acc_valid=0.9257142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 14/600 [01:34<1:34:07,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.885714285714287, test=22.78357142857142, test2V=0.090392857142857\n",
      "acc=0.9599999999999999, acc_valid=0.9257142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 15/600 [01:47<1:44:08, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.885714285714287, test=22.784999999999993, test2V=0.090392857142857\n",
      "acc=0.9614285714285713, acc_valid=0.9257142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 16/600 [02:04<2:00:54, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.885714285714287, test=22.784999999999993, test2V=0.090392857142857\n",
      "acc=0.9614285714285713, acc_valid=0.9257142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 17/600 [02:24<2:24:16, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.885714285714287, test=22.784999999999993, test2V=0.090392857142857\n",
      "acc=0.9614285714285713, acc_valid=0.9257142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 18/600 [02:47<2:48:49, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.8900000000000015, test=22.786785714285706, test2V=0.090392857142857\n",
      "acc=0.9632142857142856, acc_valid=0.9299999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 19/600 [03:11<3:06:22, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid2T=0.09039285714285712, valid=4.8900000000000015, test=22.786785714285706, test2V=0.090392857142857\n",
      "acc=0.9632142857142856, acc_valid=0.9299999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-3fe711940b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;31m# Update the target network, copying all weights and biases in DQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mTARGET_UPDATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-1cb82563ffb0>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ll5fy36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Active Learning\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "if INITIAL_FLAG:\n",
    "    pretrain_crf = pretrain_agt_list\n",
    "else:\n",
    "    pretrain_crf = test_list\n",
    "BUDGET = BUDGET - len(pretrain_agt_list) + len(pretrain_crf)\n",
    "\n",
    "crf.reset()\n",
    "crf.add_instances(pretrain_crf)\n",
    "crf.train()\n",
    "ground_list = pretrain_crf\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list])\n",
    "count = len(pretrain_crf)\n",
    "cost_list = [count]\n",
    "\n",
    "_, _, _, acc = crf.evaluate_acc(test_list)\n",
    "acc_list = [acc]\n",
    "_, _, _, acc_valid = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]\n",
    "print (acc)\n",
    "\n",
    "qvalue_list = []\n",
    "action_mark_list = []\n",
    "prob_list = []\n",
    "seq_list = []\n",
    "seqsq_list = []\n",
    "seqsr_list = []\n",
    "steps_done = 0\n",
    "try:\n",
    "    with tqdm(range(CANDIDATE_SIZE)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            if cost_list[-1] > BUDGET:\n",
    "                break\n",
    "\n",
    "            state = crf.get_parameters()\n",
    "\n",
    "            # Select and perform an action\n",
    "            act_mrk, query_idx, qvalue = select_action(state, candidate_list, GREEDY)\n",
    "            query_instance = candidate_list.pop(query_idx)\n",
    "\n",
    "            qvalue_list.append(qvalue.item())\n",
    "            action_mark_list.append(act_mrk)\n",
    "            prob_list.append(crf.compute_entropy(query_instance)[-1]/len(query_instance[0]))\n",
    "            if act_mrk == 0:\n",
    "                seqsr_list.append(query_instance)\n",
    "            else:\n",
    "                seqsq_list.append(query_instance)\n",
    "            seq_list.append(query_instance)\n",
    "\n",
    "            # Initialize the environment and state\n",
    "            ground_list = ground_list + [query_instance]\n",
    "\n",
    "            if LOOP_CANDI == 0:\n",
    "                comb = combinations(range(len(ground_list)), 3) \n",
    "            else:\n",
    "                comb = []\n",
    "                if i_episode % 10 == 0:\n",
    "                    LOOP_SIZE += 10\n",
    "                for i in range(LOOP_SIZE):\n",
    "                    comb.append(tuple(random.sample(range(len(ground_list)), LOOP_CANDI)))\n",
    "            \n",
    "            for c_idx in comb:\n",
    "                tmp_candi_list = [ground_list[i] for i in c_idx]\n",
    "                tmp_train_list = [ground_list[i] for i in range(len(ground_list)) if i not in c_idx]\n",
    "                \n",
    "                crf.reset()\n",
    "                crf.add_instances(tmp_train_list)\n",
    "                crf.train()\n",
    "\n",
    "                old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "\n",
    "                state = crf.get_parameters()\n",
    "                while len(tmp_candi_list) > 1:\n",
    "                    _, tmp_query_idx, _ = select_action(state, tmp_candi_list, GREEDY)\n",
    "                    query_instance = tmp_candi_list.pop(tmp_query_idx)\n",
    "\n",
    "                    crf.add_instances([query_instance])\n",
    "                    crf.train()\n",
    "\n",
    "                    cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                    reward = cur_reward - old_reward\n",
    "                    old_reward = cur_reward\n",
    "\n",
    "                    # Observe new state\n",
    "                    action = data.seqs2Tensor(query_instance)\n",
    "                    reward = torch.tensor([reward], device=device)\n",
    "                    next_state = crf.get_parameters()\n",
    "\n",
    "                    # Store the transition in memory\n",
    "                    memory.push(state, action, next_state, reward, [seq for seq in tmp_candi_list])\n",
    "\n",
    "                    # Move to the next state\n",
    "                    state = next_state\n",
    "\n",
    "                    # Perform one step of the optimization (on the target network)\n",
    "                    optimize_model()\n",
    "                # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "            #       target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            crf.reset()\n",
    "            crf.add_instances(ground_list)\n",
    "            crf.train()\n",
    "            \n",
    "            count += 1\n",
    "            cost_list.append(count)\n",
    "            \n",
    "            _, _, _, acc= crf.evaluate_acc(test_list)\n",
    "            acc_list.append(acc)\n",
    "            _, _, _, acc_valid= crf.evaluate_acc(validation_list)\n",
    "            acc_valid_list.append(acc_valid)\n",
    "            \n",
    "            v2t_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'valid2T')\n",
    "            v2v_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'valid2V')\n",
    "            t2t_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'test2T')\n",
    "            t2v_acc, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'test2V')\n",
    "            print ('valid2T={}, valid={}, test={}, test2V={}'.format(v2t_acc, v2v_acc, t2t_acc, t2v_acc))\n",
    "            print ('acc={}, acc_valid={}'.format(acc, acc_valid))\n",
    "            \n",
    "#             errs = []\n",
    "#             format_dict = {}\n",
    "#             for seq in test_list:\n",
    "#                 x = ''.join(seq[0])\n",
    "#                 if x not in format_dict:\n",
    "#                     format_dict[x] = 1\n",
    "#                 else: format_dict[x] += 1\n",
    "#             for k,v in format_dict.items():\n",
    "#                 format_dict[k] = v/len(test_list)\n",
    "            \n",
    "#             formats = {}\n",
    "#             for seq in test_list:\n",
    "#                 x = ''.join(seq[0])\n",
    "#                 in_acc, _, all_acc = crf.evaluate_acc([seq])\n",
    "#                 if x not in formats:\n",
    "#                     formats[x] = [format_dict[x], all_acc, format_dict[x] * (1-all_acc)]\n",
    "#             sort1_format = sorted(formats.items(), key=lambda kv: kv[1][0])[::-1]\n",
    "#             sort2_format = sorted(formats.items(), key=lambda kv: kv[1][1])\n",
    "#             sort3_format = sorted(formats.items(), key=lambda kv: kv[1][2])[::-1]\n",
    "#             sort1_list.append(sort1_format)\n",
    "#             sort2_list.append(sort2_format)\n",
    "#             sort3_list.append(sort3_format)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9449999999999998, 0.9464285714285713, 0.946785714285714, 0.9485714285714285, 0.9485714285714285, 0.9485714285714285, 0.9485714285714285, 0.9478571428571427, 0.947142857142857, 0.9489285714285713, 0.9507142857142857, 0.9503571428571428]\n",
      "[0.9175, 0.9217857142857142, 0.922142857142857, 0.9242857142857143, 0.9246428571428571, 0.9246428571428571, 0.9246428571428571, 0.9257142857142856, 0.9242857142857142, 0.9282142857142855, 0.9299999999999997, 0.929642857142857]\n",
      "[-0.36911213397979736, -0.33990561962127686, -0.4225943684577942, -0.362609326839447, -0.35844942927360535, -0.3640817403793335, -0.3800183832645416, -0.26880937814712524, -0.30037006735801697, -0.25397899746894836, -0.25433507561683655]\n",
      "reweighted acc 17.93107142857144\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_room temp,i_room temp,i_room temp\n",
      "['SODAxRxxx__ART', 1.0, 0.155, 0.155, 1.0, 0.155]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,o,b_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor\n",
      "['SODAxRxxxA_VAV', 1.0, 0.03, 0.03, 1.0, 0.03]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor\n",
      "['SODAxRxxx__VAV', 1.0, 0.035, 0.035, 1.0, 0.035]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_temp setpoint off,i_temp setpoint off,i_temp setpoint off\n",
      "['SODAxRxxx__ASO', 1.0, 0.13, 0.13, 1.0, 0.13]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_room temp setpoint,i_room temp setpoint,i_room temp setpoint\n",
      "['SODAxRxxx__ARS', 1.0, 0.13, 0.13, 1.0, 0.13]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,b_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor\n",
      "['SODAxRxxxxRVAV', 1.0, 0.01, 0.01, 1.0, 0.01]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,o,o,o,o,o,o,b_pid loop variable,i_pid loop variable,i_pid loop variable\n",
      "['SODCx______PID', 0.7857142857142857, 0.005, 0.005, 1.0, 0.003928571428571429]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_pid loop gain,i_pid loop gain,i_pid loop gain\n",
      "['SODAxRxxx__AGN', 1.0, 0.13, 0.13, 1.0, 0.13]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,o,b_room temp setpoint,i_room temp setpoint,i_room temp setpoint\n",
      "['SODAxRxxxA_ARS', 1.0, 0.025, 0.025, 1.0, 0.025]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,b_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor,i_vav reheat discharge air pressure sensor\n",
      "['SODAxRxxx_RVAV', 1.0, 0.095, 0.095, 1.0, 0.095]\n",
      "----------\n",
      "b_site,i_site,i_site,o,o,b_building wide sensor,i_building wide sensor,i_building wide sensor,o,b_hpsteam sensor,i_hpsteam sensor,i_hpsteam sensor,i_hpsteam sensor,i_hpsteam sensor\n",
      "['SOD__BLD_HPSTM', 0.6428571428571429, 0.005, 0.005, 1.0, 0.0032142857142857147]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,o,b_temp setpoint off,i_temp setpoint off,i_temp setpoint off\n",
      "['SODAxCxxxA_ASO', 1.0, 0.015, 0.015, 1.0, 0.015]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,o,b_room temp,i_room temp,i_room temp\n",
      "['SODAxRxxxA_ART', 1.0, 0.035, 0.035, 1.0, 0.035]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,i_pump,i_pump,o,o,o,b_fan speed reset,i_fan speed reset,i_fan speed reset\n",
      "['SODCxPxx___SPR', 0.42857142857142855, 0.005, 0.005, 1.0, 0.002142857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_hot water loop,i_hot water loop,b_pump,i_pump,i_pump,b_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor\n",
      "['SODHxPxxDP_STA', 0.21428571428571427, 0.005, 0.005, 1.0, 0.0010714285714285715]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,o,o,b_timer variable,i_timer variable,i_timer variable\n",
      "['SODAxRxxx__TMR', 0.7857142857142857, 0.01, 0.01, 1.0, 0.007857142857142858]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,o,o,b_curtailment override variable,i_curtailment override variable,i_curtailment override variable,i_curtailment override variable,i_curtailment override variable\n",
      "['SODAx____CURTL', 0.6428571428571429, 0.015, 0.015, 1.0, 0.009642857142857144]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,o,b_pid loop gain,i_pid loop gain,i_pid loop gain\n",
      "['SODAxRxxxB_AGN', 1.0, 0.03, 0.03, 1.0, 0.03]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,o,o,o,o,b_alarm variable,i_alarm variable,i_alarm variable\n",
      "['SODCxSP____A_M', 0.7142857142857143, 0.005, 0.005, 1.0, 0.0035714285714285718]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,o,o,b_event sensor,i_event sensor,i_event sensor,i_event sensor,i_event sensor\n",
      "['SODAx____EVENT', 1.0, 0.005, 0.005, 1.0, 0.005]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_floor,i_floor,o,b_max discharge air pressure sensor,i_max discharge air pressure sensor,i_max discharge air pressure sensor,i_max discharge air pressure sensor,i_max discharge air pressure sensor,i_max discharge air pressure sensor\n",
      "['SODAxFx_VAV_MX', 0.42857142857142855, 0.005, 0.005, 1.0, 0.002142857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,i_room,b_temp setpoint off,i_temp setpoint off,i_temp setpoint off\n",
      "['SODAxRxxx_xASO', 1.0, 0.005, 0.005, 1.0, 0.005]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,o,o,b_occupancy sensor,i_occupancy sensor,i_occupancy sensor,i_occupancy sensor,i_occupancy sensor\n",
      "['SODAx____OCCPY', 0.6428571428571429, 0.005, 0.005, 1.0, 0.0032142857142857147]\n",
      "----------\n",
      "b_site,i_site,i_site,i_site,o,b_chiller,i_chiller,i_chiller,o,b_chilled water supply temp,i_chilled water supply temp,i_chilled water supply temp,i_chilled water supply temp,i_chilled water supply temp\n",
      "['SODA_CHx_CHWST', 0.6428571428571429, 0.005, 0.005, 1.0, 0.0032142857142857147]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,b_air conditioner,i_air conditioner,i_air conditioner,o,o,o,b_status sensor,i_status sensor,i_status sensor\n",
      "['SODCxAxx___STA', 0.42857142857142855, 0.01, 0.01, 1.0, 0.004285714285714286]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,i_room,b_pid loop gain,i_pid loop gain,i_pid loop gain\n",
      "['SODAxRxxx_xAGN', 0.9285714285714286, 0.005, 0.005, 1.0, 0.004642857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_exhaust fan,i_exhaust fan,i_exhaust fan,o,o,o,b_start stop sensor,i_start stop sensor,i_start stop sensor\n",
      "['SODAxExx___S_S', 0.5714285714285714, 0.005, 0.005, 1.0, 0.002857142857142857]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,i_pump,i_pump,o,o,b_current reading,i_current reading,i_current reading\n",
      "['SODCxSPxx__AMP', 0.35714285714285715, 0.005, 0.005, 1.0, 0.0017857142857142859]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,b_low return air temp alarm,i_low return air temp alarm,i_low return air temp alarm,i_low return air temp alarm,i_low return air temp alarm,i_low return air temp alarm,i_low return air temp alarm\n",
      "['SODAx__LOW_RAT', 0.5, 0.005, 0.005, 1.0, 0.0025]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,i_pump,i_pump,o,o,b_fan speed reset,i_fan speed reset,i_fan speed reset\n",
      "['SODCxSPxx__SPD', 0.35714285714285715, 0.005, 0.005, 1.0, 0.0017857142857142859]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,i_pump,i_pump,i_pump,o,o,b_fault sensor,i_fault sensor,i_fault sensor\n",
      "['SODCxSPxx__FLT', 0.35714285714285715, 0.005, 0.005, 1.0, 0.0017857142857142859]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,i_chilled/condensor water loop,o,o,b_filtered flow sensor,i_filtered flow sensor,i_filtered flow sensor,i_filtered flow sensor,i_filtered flow sensor,i_filtered flow sensor\n",
      "['SODCxP__F_FLOW', 0.5714285714285714, 0.005, 0.005, 1.0, 0.002857142857142857]\n",
      "----------\n",
      "b_site,i_site,i_site,b_fan control unit,i_fan control unit,i_fan control unit,i_fan control unit,i_fan control unit,o,o,o,b_start stop sensor,i_start stop sensor,i_start stop sensor\n",
      "['SODFCxxA___S_S', 0.42857142857142855, 0.005, 0.005, 1.0, 0.002142857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_exhaust fan,i_exhaust fan,i_exhaust fan,o,o,o,o,o,b_status sensor,i_status sensor,i_status sensor\n",
      "['SODExx_____STA', 0.5714285714285714, 0.005, 0.005, 1.0, 0.002857142857142857]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,i_room,b_room temp,i_room temp,i_room temp\n",
      "['SODAxRxxx_xART', 1.0, 0.005, 0.005, 1.0, 0.005]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,b_air conditioner,i_air conditioner,i_air conditioner,o,o,o,b_alarm variable,i_alarm variable,i_alarm variable\n",
      "['SODCxAxx___ALM', 0.42857142857142855, 0.005, 0.005, 1.0, 0.002142857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,b_pump,i_pump,i_pump,o,o,b_failure flag,i_failure flag,i_failure flag,i_failure flag\n",
      "['SODCxPxx__FAIL', 0.35714285714285715, 0.005, 0.005, 1.0, 0.0017857142857142859]\n",
      "----------\n",
      "b_site,i_site,i_site,b_chilled/condensor water loop,i_chilled/condensor water loop,o,o,o,o,o,o,b_lead/lag sensor,i_lead/lag sensor,i_lead/lag sensor\n",
      "['SODCx______L_L', 0.7857142857142857, 0.005, 0.005, 1.0, 0.003928571428571429]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,o,o,o,o,b_outside air temp,i_outside air temp,i_outside air temp\n",
      "['SODAx______OAT', 0.7857142857142857, 0.005, 0.005, 1.0, 0.003928571428571429]\n",
      "----------\n",
      "b_site,i_site,i_site,b_hot water loop,i_hot water loop,b_pump,i_pump,i_pump,o,o,o,b_timer variable,i_timer variable,i_timer variable\n",
      "['SODHxPxx___TMR', 0.42857142857142855, 0.005, 0.005, 1.0, 0.002142857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_room,i_room,i_room,i_room,i_room,i_room,b_room temp setpoint,i_room temp setpoint,i_room temp setpoint\n",
      "['SODAxRxxx_xARS', 0.9285714285714286, 0.005, 0.005, 1.0, 0.004642857142857143]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,b_exhaust fan,i_exhaust fan,i_exhaust fan,b_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor,i_differential pressure status sensor\n",
      "['SODAxExxDP_STA', 0.35714285714285715, 0.005, 0.005, 1.0, 0.0017857142857142859]\n",
      "----------\n",
      "b_site,i_site,i_site,b_ahu,i_ahu,o,o,o,o,o,o,b_start stop sensor,i_start stop sensor,i_start stop sensor\n",
      "['SODAx______S_S', 0.7857142857142857, 0.005, 0.005, 1.0, 0.003928571428571429]\n",
      "----------\n",
      "b_site,i_site,i_site,b_condensor pump,i_condensor pump,i_condensor pump,o,o,o,o,o,b_alarm variable,i_alarm variable,i_alarm variable\n",
      "['SODCPx_____ALM', 0.5714285714285714, 0.005, 0.005, 1.0, 0.002857142857142857]\n",
      "sum acc 0.9296428571428572\n"
     ]
    }
   ],
   "source": [
    "print (acc_list)\n",
    "print (acc_valid_list)\n",
    "print (qvalue_list)\n",
    "acc, errs, _ = calculate_reward(crf, validation_list, test_list, sim_weight, 'valid2V')\n",
    "print ('reweighted acc {}'.format(acc))\n",
    "sumacc = 0\n",
    "for k, v in errs.items():\n",
    "    print ('----------')\n",
    "    print (k)\n",
    "    print (v)\n",
    "    sumacc += v[-1]\n",
    "print ('sum acc {}'.format(sumacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = \"fix\" if FIX_FLAG else \"\"\n",
    "num = \"num\" if NUM_FLAG else \"\"\n",
    "ini = \"testIni\" if not INITIAL_FLAG else \"\"\n",
    "emb = \"embed\" if EMBED_FLAG else \"\"\n",
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + num + emb + \"_\" + str(VALIDATE_SIZE) + ini + \"_\" + str(BUDGET) + \"budget_\" + TRANS + METHOD + fix + \"_\" + STRATEGY + \"_\" + GREEDY + \"_\" + REWARD\n",
    "filename += \"_\" + str(TARGET_UPDATE) + \"step_\" + str(BATCH_SIZE) + \"batch\" + str(EPS_DECAY) + \"decay_\" + str(LOOP_SIZE) + \"loop_\"\n",
    "filename += \"_\" + str(RNN_HIDDEN) + \"rnn_\" + str(N_FILTER) + \"filter_\" + str(FILTER_SIZE) + \"size_\" + str(N_STRIDE) + \"stride\"\n",
    "\n",
    "with open(filename + \".bin\", \"wb\") as result:\n",
    "    pickle.dump((cost_list, acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(errseq_list):\n",
    "    print ('----- step {} -----'.format(i))\n",
    "    for seq in seqs:\n",
    "        print (\"\".join(str(char) for char in seq[0]))\n",
    "        print (\", \".join(str(char) for char in seq[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(qvalue_list))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].plot(x, qvalue_list, color='0.5')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 1:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l1 = ax[0].scatter(x2, y2, color='r', marker='o')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 0:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l2 = ax[0].scatter(x2, y2, color='g', marker='x')\n",
    "ax[0].legend((l1,l2),\n",
    "           ('$action > \\\\epsilon$', '$action < \\\\epsilon$'))\n",
    "\n",
    "ax[0].set_title('SOD dataset with {} pretraining samples'.format(AGENT_PRETRAIN_SIZE))\n",
    "# plt.xlim(0, 20)\n",
    "ax[0].set_ylabel('Q value')\n",
    "ax[0].set_xlabel('Sequence number')\n",
    "\n",
    "# print (qvalue_list)\n",
    "ax[1].scatter(qvalue_list, prob_list)\n",
    "for i in range(len(qvalue_list)):\n",
    "    ax[1].annotate(i, (qvalue_list[i], prob_list[i]))\n",
    "ax[1].set_xlabel('Q value')\n",
    "ax[1].set_ylabel('Likelihood')\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "fig.set_size_inches(15,5)\n",
    "# plt.show()\n",
    "plt.savefig(filename + '_check.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sim beta\n",
    "with open(\"./results/sod15_200_acc2_fully_none.bin\", \"rb\") as in_file:\n",
    "    (cost_1, _, _, all_acc_1, acc_valid_1) = pickle.load(in_file)\n",
    "#     (cost_1, all_acc_1, acc_valid_1) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod15num_200_75budget_test2TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_2, all_acc_2, acc_valid_2) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod15num_200_75budget_valid2TRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_3, all_acc_3, acc_valid_3) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod15num_200_75budget_valid2VRL_all_te_acc_20step_5batch20decay_90loop-add10each10step-3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_4, all_acc_4, acc_valid_4) = pickle.load(in_file)\n",
    "    \n",
    "# with open(\"./results/sod15num_200_valid2TRL_all_te_acc_20step_5batch20decay_90loop3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_5, all_acc_5, acc_valid_5) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_testVRL_acc2_all_rand_20step_5batch20decay_90loopdecay_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_6, in_acc_6, out_acc_6, all_acc_6, acc_valid_6) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_testVRL_acc2_all_te_20step_5batch20decay_90loopdecay_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_7, in_acc_7, out_acc_7, all_acc_7, acc_valid_7) = pickle.load(in_file)\n",
    "\n",
    "plt.plot(cost_1, all_acc_1,\n",
    "         cost_2, all_acc_2,\n",
    "         cost_3, all_acc_3,\n",
    "         cost_4, all_acc_4,)\n",
    "#          cost_5, all_acc_5,)\n",
    "#          cost_6, all_acc_6,)\n",
    "#          cost_7, acc_valid_7)\n",
    "plt.legend(['TE', 'test2T', 'valid2T', 'valid2V', 'valid2T' ,'RL-test', 'RL-valid'], loc='upper left', fancybox=True, fontsize = 9)\n",
    "# plt.xlim(200, 600)\n",
    "\n",
    "plt.title('CoNLL dataset with 15 pretraining samples')\n",
    "plt.xlabel('Number of training sequences')\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.savefig('./results/sod.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "SUBSEQ_FLAG = False\n",
    "SUBSEQ_SIZE = 8\n",
    "STRATEGY = 'fully'\n",
    "BETA = 3.0\n",
    "METHOD = 'random' #selfSim, testSim\n",
    "\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "crf = CrfModel(data, FEAT)\n",
    "crf.add_instances(pretrain_agt_list)\n",
    "crf.train()\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list]) \n",
    "count = len(pretrain_agt_list)\n",
    "cost_list = [count]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "\n",
    "in_acc_list = [in_acc]\n",
    "out_acc_list = [out_acc]\n",
    "all_acc_list = [acc]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized and clustered test set.\n",
    "Xs = [seq[0] for seq in test_list]\n",
    "Xs.extend([seq[0] for seq in candidate_list])\n",
    "vec, _ = string_vectorize(Xs)\n",
    "validation_vec = vec[:len(test_list)].tolist()\n",
    "candidate_vec = vec[len(test_list):].tolist()\n",
    "\n",
    "print (len(validation_vec))\n",
    "print (len(candidate_vec))\n",
    "# Pre-calculate similarity: both between validation-test and validation-validate\n",
    "sim_matrix_test = np.zeros((len(candidate_vec), len(validation_vec)))\n",
    "sim_matrix_self = np.zeros((len(candidate_vec), len(candidate_vec)))\n",
    "if METHOD != 'none' and METHOD != 'random':\n",
    "    iterator = tqdm(range(len(candidate_vec)))\n",
    "    for i in iterator:\n",
    "        for j in range(len(validation_vec)):\n",
    "            sim_matrix_test[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], validation_vec[j])\n",
    "        for j in range(len(candidate_vec)):\n",
    "            sim_matrix_self[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], candidate_vec[j])\n",
    "    iterator.close()\n",
    "print ('Similarity done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visited_candidate_idx = []\n",
    "seqs_list = []\n",
    "iterator = tqdm(range(CANDIDATE_SIZE))\n",
    "for seqs_size in iterator:\n",
    "    if cost_list[-1] > BUDGET:\n",
    "        break\n",
    "    \n",
    "    # Sort the test set based on confidence.\n",
    "    prob_test_list = []\n",
    "    for i in range(len(test_list)):\n",
    "        (prob_per_token, _, prob_sum) = crf.compute_confidence(test_list[i])\n",
    "        prob_test_list.append(prob_sum)\n",
    "    rank_idx_test = np.argsort(np.array(prob_test_list), kind='mergesort').tolist()[::-1]\n",
    "\n",
    "    # Calculate the average similarity between the unlabeled samples and the selected test samples.\n",
    "    distance = []\n",
    "    if METHOD == 'testSim':\n",
    "        distance = np.sum(sim_matrix_test[:, rank_idx_test[:M]], axis=1) / M\n",
    "    elif METHOD == 'selfSim':\n",
    "        distance = np.sum(sim_matrix_self, axis=1) / (len(candidate_vec)-1)\n",
    "        \n",
    "\n",
    "    ####\n",
    "    # Compute the top-K tokens and its seq_idx: subsequence with or without SEBSEQ_FLAG\n",
    "    prob_list = []\n",
    "    subseq_idx_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        (prob_per_token, prob_sum) = crf.compute_entropy(candidate_list[i])\n",
    "        prob_sum /= len(candidate_list[i][1])\n",
    "        if STRATEGY == 'partial':\n",
    "            subseq_idxs = []\n",
    "            subseq_prob_sum = -sys.maxsize\n",
    "            if SUBSEQ_FLAG:\n",
    "                end_p = len(prob_per_token) - SUBSEQ_SIZE + 1\n",
    "                for k in range(0, end_p): # the largest subsequence\n",
    "                    prob_tmp = sum([prob_per_token[k+j] for j in range(SUBSEQ_SIZE)]) / SUBSEQ_SIZE\n",
    "                    if prob_tmp > subseq_prob_sum:\n",
    "                        subseq_prob_sum = prob_tmp\n",
    "                        subseq_idxs = [k+j for j in range(SUBSEQ_SIZE)]\n",
    "                if end_p < 1: # if length is not longer than subseq_size\n",
    "                    subseq_prob_sum = prob_sum / len(prob_per_token)\n",
    "                    subseq_idxs = range(0, len(prob_per_token))\n",
    "            else:\n",
    "                token_sorted = np.argsort(np.array(prob_per_token), kind='mergesort').tolist()[::-1]\n",
    "                subseq_idxs = [token_sorted[k] for k in range(min(SUBSEQ_SIZE, len(prob_per_token)))]\n",
    "                subseq_prob_sum = sum([prob_per_token[k] for k in subseq_idxs]) / len(subseq_idxs)\n",
    "            prob_sum = subseq_prob_sum\n",
    "            subseq_idx_list.append(subseq_idxs)\n",
    "\n",
    "        prob_list.append(prob_sum)\n",
    "    \n",
    "    # Entropy weighted with or without similarity\n",
    "    mean_prob = np.mean(prob_list)\n",
    "    std_prob = np.std(prob_list)\n",
    "    prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(candidate_list))]\n",
    "\n",
    "    # norm_dist = [1/(1+math.exp(x)) for x in norm_dist]\n",
    "    score_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        if METHOD == 'none':\n",
    "            score_list.append(prob_list[i])\n",
    "        elif METHOD != 'random':\n",
    "            score_list.append(prob_list[i] * math.pow(distance[i], BETA))\n",
    "    \n",
    "    # Locate the subseq_idx with largest score\n",
    "    rank_idx = np.argsort(np.array(score_list), kind='mergesort').tolist()[::-1]\n",
    "    if METHOD == 'random':\n",
    "        rand_idx = random.shuffle(list(range(len(score_list))))\n",
    "        \n",
    "    for i in rank_idx:\n",
    "        if i not in visited_candidate_idx:\n",
    "            seq_idx = i\n",
    "            visited_candidate_idx.append(seq_idx)\n",
    "            break\n",
    "    query_seq = candidate_list[seq_idx]\n",
    "    \n",
    "    if STRATEGY == 'partial':\n",
    "        subseq_idxs = subseq_idx_list[seq_idx]\n",
    "        predict_y = crf.predict(query_seq)\n",
    "        for i in range(len(query_seq[1])):\n",
    "            if i not in subseq_idxs:\n",
    "                query_seq[1][i] = predict_y[i]\n",
    "        count += len(subseq_idxs)\n",
    "    else:\n",
    "#         count += len(query_seq[1])\n",
    "        count += 1\n",
    "    cost_list.append(count)\n",
    "    \n",
    "    crf.add_instances([query_seq])\n",
    "    seqs_list.append(query_seq)\n",
    "    crf.train()\n",
    "    (in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "    in_acc_list.append(in_acc)\n",
    "    out_acc_list.append(out_acc)\n",
    "    all_acc_list.append(acc)\n",
    "    \n",
    "    (in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "    acc_valid_list.append(acc_valid)\n",
    "iterator.close()\n",
    "print ('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + \"_\" + str(VALIDATE_SIZE) + \"_\" + str(BUDGET) + \"budget_\" + STRATEGY + \"_\" + METHOD \n",
    "if STRATEGY == 'partial':\n",
    "    filename += \"_sub\" + str(SUBSEQ_SIZE) + str(SUBSEQ_FLAG)\n",
    "if METHOD != 'none' and METHOD != 'random':\n",
    "    filename += \"_beta\" + str(BETA)\n",
    "    if METHOD == 'testSim':\n",
    "        filename += \"_M\" + str(M)\n",
    "filename += \".bin\"\n",
    "\n",
    "with open(filename, \"wb\") as result:\n",
    "    pickle.dump((cost_list, in_acc_list, out_acc_list, all_acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_q = gen_dataDistr(seqsq_list + pretrain_agt_list)\n",
    "rand_q = gen_dataDistr(seqsr_list + pretrain_agt_list)\n",
    "print (\"selected set has {} formats\".format(len(select_q)))\n",
    "print (\"rand set has {} formats\".format(len(rand_q)))\n",
    "\n",
    "# for rank, key in enumerate(sorted(uniques, key=uniques.get, reverse=True), 1):\n",
    "#     print (rank, key)\n",
    "\n",
    "data_dict = add_dataformat({}, test_list)\n",
    "data_dict = add_dataformat(data_dict, validation_list)\n",
    "data_dict = add_dataformat(data_dict, seqsq_list + seqsr_list + pretrain_agt_list)\n",
    "data_dict = add_dataformat(data_dict, candidate_list)\n",
    "print (\"{} formats overall\".format(len(data_dict)))\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    print (\"{}: {}\".format(key, str(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_ratio = len(set.intersection(set(test_q.keys()),set(select_q.keys()))) / len(test_q)\n",
    "print (\"select & test / test: {}\".format(select_test_ratio))\n",
    "\n",
    "select_valid_ratio = len(set.intersection(set(valid_q.keys()),set(select_q.keys()))) / len(valid_q)\n",
    "print (\"select & valid / valid: {}\".format(select_valid_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "for key, value in test_q.items():\n",
    "    x1.append(data_dict[key])\n",
    "    y1.append(value)\n",
    "l1 = plt.bar(x1, y1)\n",
    "\n",
    "x2 = []\n",
    "y2 = []\n",
    "for key, value in valid_q.items():\n",
    "    x2.append(data_dict[key])\n",
    "    y2.append(value)\n",
    "l2 = plt.bar(x2, y2)\n",
    "\n",
    "x3 = []\n",
    "y3 = []\n",
    "for key, value in select_q.items():\n",
    "    x3.append(data_dict[key])\n",
    "    y3.append(value)\n",
    "l3 = plt.bar(x3, y3)\n",
    "\n",
    "x4 = []\n",
    "y4 = []\n",
    "for key, value in rand_q.items():\n",
    "    x4.append(data_dict[key])\n",
    "    y4.append(value)\n",
    "l4 = plt.bar(x4, y4)\n",
    "\n",
    "plt.title('data distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.legend((l1, l2, l3, l4), ('test', 'validation', 'select', 'rand'))\n",
    "# plt.show()\n",
    "\n",
    "# x4 = []\n",
    "# y4 = []\n",
    "# for key, value in candidate_q.items():\n",
    "#     x4.append(data_dict[key])\n",
    "#     y4.append(value)\n",
    "# plt.bar(x4, y4)\n",
    "# plt.title('candidate distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.savefig(filename + '_distr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results1/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/sod1000_fully_selfSim_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod_partial_selfSim_sub8False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod1000_partial_selfSim_sub8False_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_self_part, in_acc_self_part, out_acc_self_part, all_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sod_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_test_part, in_acc_test_part, out_acc_test_part, all_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='serif')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, linestyle='--')\n",
    "ax[0].plot(cost_9, all_acc_9)\n",
    "ax[0].plot(cost_11, all_acc_11)\n",
    "ax[0].plot(cost_self_part, all_acc_self_part)\n",
    "ax[0].plot(cost_test_part, all_acc_test_part, c='black')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results1/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/sdh_fully_selfSim_beta1.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh_partial_selfSim_sub8False_beta0.5_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_self_part, in2_acc_self_part, out_acc_self_part, all2_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/sdh1000_partial_testSim_sub8False_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_test_part, in2_acc_test_part, out_acc_test_part, all2_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, linestyle='--')\n",
    "ax[1].plot(cost2_9, all2_acc_9)\n",
    "ax[1].plot(cost2_11, all2_acc_11)\n",
    "ax[1].plot(cost2_self_part, all2_acc_self_part)\n",
    "ax[1].plot(cost2_test_part, all2_acc_test_part, c='black')\n",
    "ax[1].set_ylim([0.85, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results1/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results1/ibm1000_partial_testSim_sub13False_beta1.0_M10_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results1/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_partial_selfSim_sub17False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_self_part, in3_acc_self_part, out_acc_self_part, all3_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results1/ibm_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_test_part, in3_acc_test_part, out_acc_test_part, all3_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=\":\")\n",
    "ax[2].plot(cost3_8, all3_acc_8, linestyle='--')\n",
    "ax[2].plot(cost3_9, all3_acc_9)\n",
    "ax[2].plot(cost3_11, all3_acc_11)\n",
    "ax[2].plot(cost3_self_part, all3_acc_self_part)\n",
    "ax[2].plot(cost3_test_part, all3_acc_test_part, c='black')\n",
    "ax[2].set_ylim([0.745, 0.924])\n",
    "ax[2].set_xlim([200,1000])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod1000_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod_partial_none_sub12False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='arial')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, c='orange')\n",
    "ax[0].plot(cost_9, all_acc_9, c='green')\n",
    "ax[0].plot(cost_11, all_acc_11, c='red')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['Full', r'w=5', r'w=9', r'w=12'], loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sdh_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh_partial_none_sub14False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, c='orange')\n",
    "ax[1].plot(cost2_9, all2_acc_9, c='green')\n",
    "ax[1].plot(cost2_11, all2_acc_11, c='red')\n",
    "ax[1].set_ylim([0.83, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['Full', 'w=5', 'w=8', 'w=14'],\n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/ibm_partial_none_sub11False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_partial_none_sub7False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=':')\n",
    "ax[2].plot(cost3_8, all3_acc_8, c='orange')\n",
    "ax[2].plot(cost3_9, all3_acc_9, c='green')\n",
    "ax[2].plot(cost3_11, all3_acc_11, c='red')\n",
    "ax[2].set_xlim([200,1000])\n",
    "# ax[2].set_ylim([0.83, 0.978])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['Full', 'w=15', 'w=19', 'w=23'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()\n",
    "# plt.tick_params(labelsize=20)\n",
    "# plt.savefig('perp1.png', bbox_inches='tight')\n",
    "    \n",
    "# plt.plot(cost_f, all_acc_f,\n",
    "#          cost_8, all_acc_8,\n",
    "#          cost_9, all_acc_9,\n",
    "#          cost_11, all_acc_11,\n",
    "#          cost_self_part, all_acc_self_part,\n",
    "#          cost_test_part, all_acc_test_part)\n",
    "# plt.legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], loc='lower right', fancybox=True, fontsize = 12)\n",
    "# # plt.ylim(0.86, 0.97)\n",
    "\n",
    "# plt.title('SOD dataset with 5 pretraining samples')\n",
    "# plt.xlabel('Number of training labels')\n",
    "# plt.ylabel('Prediction accuracy')\n",
    "# plt.savefig('./results/sod.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "ll5fy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
